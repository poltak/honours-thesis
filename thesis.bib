@inproceedings{toshniwal_stormtwitter_2014,
  address = {New York, {NY}, {USA}},
  series = {{SIGMOD} '14},
  title = {Storm@{T}witter},
  isbn = {978-1-4503-2376-5},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/2588555.2595641},
  doi = {10.1145/2588555.2595641},
  abstract = {This paper describes the use of Storm at Twitter. Storm is a real-time fault-tolerant and distributed stream data processing system. Storm is currently being used to run various critical computations in Twitter at scale, and in real-time. This paper describes the architecture of Storm and its methods for distributed scale-out and fault-tolerance. This paper also describes how queries (aka. topologies) are executed in Storm, and presents some operational stories based on running Storm at Twitter. We also present results from an empirical evaluation demonstrating the resilience of Storm in dealing with machine failures. Storm is under active development at Twitter and we also present some potential directions for future work.},
  urldate = {2014-08-11},
  booktitle = {Proceedings of the 2014 {ACM} {SIGMOD} International Conference on Management of Data},
  publisher = {{ACM}},
  author = {Toshniwal, Ankit and Taneja, Siddarth and Shukla, Amit and Ramasamy, Karthik and Patel, Jignesh M. and Kulkarni, Sanjeev and Jackson, Jason and Gade, Krishna and Fu, Maosong and Donham, Jake and Bhagat, Nikunj and Mittal, Sailesh and Ryaboy, Dmitriy},
  year = {2014},
  keywords = {real-time query processing, stream data management},
  pages = {147–156}
}

@incollection{bohlouli_towards_2013,
  title = {Towards an integrated platform for big data analysis},
  url = {http://link.springer.com.ezproxy.lib.monash.edu.au/chapter/10.1007/978-3-642-34471-8_4},
  urldate = {2014-08-25},
  booktitle = {Integration of Practice-Oriented Knowledge Technology: Trends and Prospectives},
  publisher = {Springer},
  author = {Bohlouli, Mahdi and Schulz, Frank and Angelis, Lefteris and Pahor, David and Brandic, Ivona and Atlan, David and Tate, Rosemary},
  year = {2013},
  pages = {47--56}
}

@misc{web:Storm,
  title = {Storm, distributed and fault-tolerant realtime computation},
  year = {2013},
  month = {November},
  howpublished = {\mbox{\url{http://storm-project.net}}}
}

@misc{web:synchrotron,
  title = {Australian {S}ynchrotron},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{https://www.synchrotron.org.au}}}
}

@misc{web:LHC,
  title = {The {L}arge {H}adron {C}ollider | {CERN}},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{http://home.web.cern.ch/topics/large-hadron-collider}}}
}

@misc{web:Amazon,
  title = {Amazon.com: {O}nline {S}hopping for {E}lectronics, {A}pparel, {C}omputers, {B}ooks, {DVD}s \& more},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{http://www.amazon.com}}}
}

@misc{web:SparkStreaming,
  title = {Spark {S}treaming | {A}pache {S}park},
  year = {2014},
  howpublished = {\mbox{\url{https://spark.apache.org/streaming/}}}
}

@misc{web:UCBerkelyAMCLab,
  title = {AMPLab - {UC} {B}erkeley | {A}lgorithms, {M}achines and {P}eople {L}ab},
  year = {2014},
  howpublished = {\mbox{\url{https://amplab.cs.berkeley.edu}}}
}

@misc{web:Spark,
  title = {Apache {S}park\texttrademark -- {L}ightning-{F}ast {C}luster {C}omputing},
  year = {2014},
  howpublished = {\mbox{\url{https://spark.apache.org}}}
}

@inproceedings{liu_survey_2014,
  address = {New York, {NY}, {USA}},
  series = {{IDEAS} '14},
  title = {Survey of Real-time Processing Systems for Big Data},
  isbn = {978-1-4503-2627-8},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/2628194.2628251},
  doi = {10.1145/2628194.2628251},
  urldate = {2014-08-25},
  booktitle = {Proceedings of the 18th International Database Engineering \&\#38; Applications Symposium},
  publisher = {{ACM}},
  author = {Liu, Xiufeng and Iftikhar, Nadeem and Xie, Xike},
  year = {2014},
  keywords = {architectures, big data, real-time, survey, systems},
  pages = {356--361}
}

@misc{web:Nectar,
  title = {home | {NeCTAR}},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{http://www.nectar.org.au}}}
}

@inproceedings{klimt2004introducing,
  title={Introducing the Enron Corpus.},
  author={Klimt, Bryan and Yang, Yiming},
  booktitle={CEAS},
  year={2004}
}


@inproceedings{sinnott_towards_2011,
  title = {Towards an e-infrastructure for urban research across Australia},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6123291},
  urldate = {2014-08-30},
  booktitle = {E-Science (e-Science), 2011 {IEEE} 7th International Conference on},
  publisher = {{IEEE}},
  author = {Sinnott, Richard O. and Galang, Gerson and Tomko, Martin and Stimson, Robert},
  year = {2011},
  pages = {295--302},
  file = {[PDF] from unimelb.edu.au:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/5HT2S9FW/Sinnott et al. - 2011 - Towards an e-infrastructure for urban research acr.pdf:application/pdf;Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/TU6W5AK5/login.html:text/html}
}

@book{marz2013principles,
  added-at = {2013-08-23T14:45:17.000+0200},
  address = {[S.l.]},
  author = {Marz, Nathan},
  biburl = {http://www.bibsonomy.org/bibtex/20dc290e810c709342f645179a9098cba/becker},
  description = {Big Data: Principles and Best Practices of Scalable Realtime Data Systems: Amazon.de: Nathan Marz, James Warren: Englische Bücher},
  interhash = {64a1336f5e196af365ef409e9ace3fa3},
  intrahash = {0dc290e810c709342f645179a9098cba},
  isbn = {1617290343 9781617290343},
  keywords = {big data lambda principles s:2013-08-23_sensorplatforms},
  publisher = {O'Reilly Media},
  refid = {810318817},
  timestamp = {2013-08-23T14:45:17.000+0200},
  title = {Big data : principles and best practices of scalable realtime data systems},
  url = {http://www.amazon.de/Big-Data-Principles-Practices-Scalable/dp/1617290343},
  year = 2013
}


@article{bifet_mining_2013,
  title = {Mining big data in real time},
  volume = {37},
  issn = {03505596},
  url = {http://go.galegroup.com/ps/i.do?id=GALE%7CA329730435&v=2.1&u=monash&it=r&p=AONE&sw=w&asid=43dd70afff364e9b2d73c1537dfe198a},
  language = {English},
  number = {1},
  urldate = {2014-08-11},
  journal = {Informatica},
  author = {Bifet, Albert},
  month = mar,
  year = {2013},
  keywords = {big data, Data mining},
  pages = {15+}
}


@inproceedings{ghemawat_google_2003,
  address = {New York, {NY}, {USA}},
  series = {{SOSP} '03},
  title = {The Google File System},
  isbn = {1-58113-757-5},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/945445.945450},
  doi = {10.1145/945445.945450},
  urldate = {2014-08-31},
  booktitle = {Proceedings of the Nineteenth {ACM} Symposium on Operating Systems Principles},
  publisher = {{ACM}},
  author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
  year = {2003},
  keywords = {clustered storage, data storage, fault tolerance, scalability},
  pages = {29--43}
}


@article{dean_mapreduce:_2008,
  title = {{MapReduce}: Simplified Data Processing on Large Clusters},
  volume = {51},
  issn = {0001-0782},
  shorttitle = {{MapReduce}},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/1327452.1327492},
  doi = {10.1145/1327452.1327492},
  abstract = {{MapReduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct {MapReduce} programs have been implemented internally at Google over the past four years, and an average of one hundred thousand {MapReduce} jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
  number = {1},
  urldate = {2014-08-31},
  journal = {Commun. {ACM}},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  month = jan,
  year = {2008},
  pages = {107--113}
}


@inproceedings{shvachko_hadoop_2010,
  title = {The Hadoop Distributed File System},
  doi = {10.1109/MSST.2010.5496972},
  abstract = {The Hadoop Distributed File System ({HDFS}) is designed to store very large data sets reliably, and to stream those data sets at high bandwidth to user applications. In a large cluster, thousands of servers both host directly attached storage and execute user application tasks. By distributing storage and computation across many servers, the resource can grow with demand while remaining economical at every size. We describe the architecture of {HDFS} and report on experience using {HDFS} to manage 25 petabytes of enterprise data at Yahoo!.},
  booktitle = {2010 {IEEE} 26th Symposium on Mass Storage Systems and Technologies ({MSST})},
  author = {Shvachko, K. and Kuang, Hairong and Radia, S. and Chansler, R.},
  month = may,
  year = {2010},
  keywords = {Bandwidth, Clustering algorithms, Computer architecture, Concurrent computing, data storage, data stream, Distributed computing, distributed databases, distributed file system, enterprise data, Facebook, File servers, File systems, Hadoop, Hadoop distributed file system, {HDFS}, Internet, network operating systems, Protection, Protocols, Yahoo!},
  pages = {1--10},
  file = {IEEE Xplore Abstract Record:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/5NSM8DN7/login.html:text/html}
}


@inproceedings{olston_pig_2008,
  address = {New York, {NY}, {USA}},
  series = {{SIGMOD} '08},
  title = {Pig Latin: A Not-so-foreign Language for Data Processing},
  isbn = {978-1-60558-102-6},
  shorttitle = {Pig Latin},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/1376616.1376726},
  doi = {10.1145/1376616.1376726},
  abstract = {There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where innovation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, offer a solution, but are usually prohibitively expensive at this scale. Besides, many of the people who analyze this data are entrenched procedural programmers, who find the declarative, {SQL} style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hardware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse. We describe a new language called Pig Latin that we have designed to fit in a sweet spot between the declarative style of {SQL}, and the low-level, procedural style of map-reduce. The accompanying system, Pig, is fully implemented, and compiles Pig Latin into physical plans that are executed over Hadoop, an open-source, map-reduce implementation. We give a few examples of how engineers at Yahoo! are using Pig to dramatically reduce the time required for the development and execution of their data analysis tasks, compared to using Hadoop directly. We also report on a novel debugging environment that comes integrated with Pig, that can lead to even higher productivity gains. Pig is an open-source, Apache-incubator project, and available for general use.},
  urldate = {2014-08-17},
  booktitle = {Proceedings of the 2008 {ACM} {SIGMOD} International Conference on Management of Data},
  publisher = {{ACM}},
  author = {Olston, Christopher and Reed, Benjamin and Srivastava, Utkarsh and Kumar, Ravi and Tomkins, Andrew},
  year = {2008},
  keywords = {dataflow language, pig latin},
  pages = {1099--1110}
}


@inproceedings{thusoo_hive_2010,
  title = {Hive - a petabyte scale data warehouse using Hadoop},
  doi = {10.1109/ICDE.2010.5447738},
  abstract = {The size of data sets being collected and analyzed in the industry for business intelligence is growing rapidly, making traditional warehousing solutions prohibitively expensive. Hadoop is a popular open-source map-reduce implementation which is being used in companies like Yahoo, Facebook etc. to store and process extremely large data sets on commodity hardware. However, the map-reduce programming model is very low level and requires developers to write custom programs which are hard to maintain and reuse. In this paper, we present Hive, an open-source data warehousing solution built on top of Hadoop. Hive supports queries expressed in a {SQL}-like declarative language - {HiveQL}, which are compiled into map-reduce jobs that are executed using Hadoop. In addition, {HiveQL} enables users to plug in custom map-reduce scripts into queries. The language includes a type system with support for tables containing primitive types, collections like arrays and maps, and nested compositions of the same. The underlying {IO} libraries can be extended to query data in custom formats. Hive also includes a system catalog - Metastore - that contains schemas and statistics, which are useful in data exploration, query optimization and query compilation. In Facebook, the Hive warehouse contains tens of thousands of tables and stores over 700TB of data and is being used extensively for both reporting and ad-hoc analyses by more than 200 users per month.},
  booktitle = {2010 {IEEE} 26th International Conference on Data Engineering ({ICDE})},
  author = {Thusoo, A and Sarma, J.S. and Jain, N. and Shao, Zheng and Chakka, P. and Zhang, Ning and Antony, S. and Liu, Hao and Murthy, R.},
  month = mar,
  year = {2010},
  keywords = {arrays, business intelligence, Companies, competitive intelligence, data exploration, data warehouses, Facebook, Hadoop software, Hardware, {HiveQL} language, Libraries, map-reduce jobs, maps, Metastore system catalog, nested compositions, open-source map-reduce implementation, Open source software, petabyte scale data warehouse, Plugs, primitive types, public domain software, query compilation, query optimization, query processing, {SQL}, {SQL}-like declarative language, Statistics, Warehousing},
  pages = {996--1005},
  file = {IEEE Xplore Abstract Record:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/JNB3RPAD/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/E5VJFX8C/Thusoo et al. - 2010 - Hive - a petabyte scale data warehouse using Hadoo.pdf:application/pdf}
}


@article{gates_building_2009,
  title = {Building a High-level Dataflow System on Top of Map-Reduce: The Pig Experience},
  volume = {2},
  issn = {2150-8097},
  shorttitle = {Building a High-level Dataflow System on Top of Map-Reduce},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.14778/1687553.1687568},
  doi = {10.14778/1687553.1687568},
  abstract = {Increasingly, organizations capture, transform and analyze enormous data sets. Prominent examples include internet companies and e-science. The Map-Reduce scalable dataflow paradigm has become popular for these applications. Its simple, explicit dataflow programming model is favored by some over the traditional high-level declarative approach: {SQL}. On the other hand, the extreme simplicity of Map-Reduce leads to much low-level hacking to deal with the many-step, branching dataflows that arise in practice. Moreover, users must repeatedly code standard operations such as join by hand. These practices waste time, introduce bugs, harm readability, and impede optimizations. Pig is a high-level dataflow system that aims at a sweet spot between {SQL} and Map-Reduce. Pig offers {SQL}-style high-level data manipulation constructs, which can be assembled in an explicit dataflow and interleaved with custom Map- and Reduce-style functions or executables. Pig programs are compiled into sequences of Map-Reduce jobs, and executed in the Hadoop Map-Reduce environment. Both Pig and Hadoop are open-source projects administered by the Apache Software Foundation. This paper describes the challenges we faced in developing Pig, and reports performance comparisons between Pig execution and raw Map-Reduce execution.},
  number = {2},
  urldate = {2014-08-31},
  journal = {Proc. {VLDB} Endow.},
  author = {Gates, Alan F. and Natkovich, Olga and Chopra, Shubham and Kamath, Pradeep and Narayanamurthy, Shravan M. and Olston, Christopher and Reed, Benjamin and Srinivasan, Santhosh and Srivastava, Utkarsh},
  month = aug,
  year = {2009},
  pages = {1414--1425}
}


@inproceedings{vavilapalli_apache_2013,
  address = {New York, {NY}, {USA}},
  series = {{SOCC} '13},
  title = {Apache Hadoop {YARN}: Yet Another Resource Negotiator},
  isbn = {978-1-4503-2428-1},
  shorttitle = {Apache Hadoop {YARN}},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/2523616.2523633},
  doi = {10.1145/2523616.2523633},
  abstract = {The initial design of Apache Hadoop [1] was tightly focused on running massive, {MapReduce} jobs to process a web crawl. For increasingly diverse companies, Hadoop has become the data and computational agorá---the de facto place where data and computational resources are shared and accessed. This broad adoption and ubiquitous usage has stretched the initial design well beyond its intended target, exposing two key shortcomings: 1) tight coupling of a specific programming model with the resource management infrastructure, forcing developers to abuse the {MapReduce} programming model, and 2) centralized handling of jobs' control flow, which resulted in endless scalability concerns for the scheduler. In this paper, we summarize the design, development, and current state of deployment of the next generation of Hadoop's compute platform: {YARN}. The new architecture we introduced decouples the programming model from the resource management infrastructure, and delegates many scheduling functions (e.g., task fault-tolerance) to per-application components. We provide experimental evidence demonstrating the improvements we made, confirm improved efficiency by reporting the experience of running {YARN} on production environments (including 100\% of Yahoo! grids), and confirm the flexibility claims by discussing the porting of several programming frameworks onto {YARN} viz. Dryad, Giraph, Hoya, Hadoop {MapReduce}, {REEF}, Spark, Storm, Tez.},
  urldate = {2014-08-14},
  booktitle = {Proceedings of the 4th Annual Symposium on Cloud Computing},
  publisher = {{ACM}},
  author = {Vavilapalli, Vinod Kumar and Murthy, Arun C. and Douglas, Chris and Agarwal, Sharad and Konar, Mahadev and Evans, Robert and Graves, Thomas and Lowe, Jason and Shah, Hitesh and Seth, Siddharth and Saha, Bikas and Curino, Carlo and O'Malley, Owen and Radia, Sanjay and Reed, Benjamin and Baldeschwieler, Eric},
  year = {2013},
  pages = {5:1--5:16}
}


@article{harrison_hadoops_2012,
  title = {Hadoop's Next-Generation {YARN}},
  volume = {26},
  copyright = {Copyright Information Today, Inc. Dec 2012},
  issn = {1547-9897},
  url = {http://search.proquest.com.ezproxy.lib.monash.edu.au/docview/1265616176?accountid=12528},
  abstract = {As the undisputed pioneer of big data, Google established most of the key technologies underlying Hadoop and many of the {NoSQL} databases. The Google File System ({GFS}) allowed dusters of commodity servers to present their internal disk storage as a unified file system and inspired the Hadoop Distributed File System ({HDFS}). Google's column-oriented key value store {BigTable} influenced many {NoSQL} systems such as Apache {HBase}, Cassandra and {HyperTable}. And, of course, the Google {MapReduce} algorithm became the foundation computing model for Hadoop and was widely implemented in other {NoSQL} systems such as {MongoDB}.
{YARN} provides much more than just improved scalability, however; it treats traditional {MapReduce} as just one of the possible frameworks that can run on the cluster. {YARN}, therefore, will allow Hadoop clusters to execute non-{MapReduce} workloads. Work is underway on a number of such applications, including Spark, Storm, Giraph, and Hama.
Only the very largest Hadoop users are likely to benefit from {YARN}'s scalability improvements. For the rest of us, the ability to extend the range of Hadoop analytics is far more significant. At the end of the day, a Hadoop cluster is only as valuable as the analytic insights it can provide. By extending the range of possible analytic models, {YARN} should contribute to the long-term success of Hadoop.},
  language = {English},
  number = {4},
  urldate = {2014-08-11},
  journal = {Database Trends and Applications},
  author = {Harrison, Guy},
  month = dec,
  year = {2012},
  keywords = {Computers, Data bases, Product development, {SQL}},
  pages = {39}
}

@article{kamburugamuve_survey_2014,
  title = {Survey of Distributed Stream Processing for Large Stream Sources},
  url = {http://www.sics.se/~amir/files/download/dic/2013%20-%20Survey%20of%20Distributed%20Stream%20Processing%20for%20Large%20Stream%20Sources.pdf},
  urldate = {2014-08-31},
  author = {Kamburugamuve, Supun and Fox, Geoffrey and Leake, David and Qiu, Judy},
  file = {[PDF] from sics.se:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/92IIH8C2/Kamburugamuve et al. - Survey of Distributed Stream Processing for Large .pdf:application/pdf},
  year = {2014}
}

@misc{web:Samza,
  title = {Samza},
  year = {2014},
  howpublished = {\mbox{\url{http://samza.incubator.apache.org}}}
}


@book{islam_cloud_2014,
  title = {A Cloud Based Platform for Big Data Science},
  url = {http://www.diva-portal.org/smash/record.jsf?pid=diva2:690525},
  abstract = {With the advent of cloud computing, resizable scalable infrastructures for data processing is now available to everyone. Software platforms and frameworks that support data intensive distributed ap ...},
  language = {eng},
  urldate = {2014-08-31},
  author = {Islam, Md Zahidul},
  year = {2014},
  note = {With the advent of cloud computing, resizable scalable infrastructures for data processing is now available to everyone. Software platforms and frameworks that support data intensive distributed ap ...},
  keywords = {Programvaruteknik, Software Engineering},
  file = {Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/J7Q6THMQ/record.html:text/html}
}

@article{DBLP:journals/corr/XinCDGFS14,
  author    = {Reynold S. Xin and
               Daniel Crankshaw and
               Ankur Dave and
               Joseph E. Gonzalez and
               Michael J. Franklin and
               Ion Stoica},
  title     = {GraphX: Unifying Data-Parallel and Graph-Parallel Analytics},
  journal   = {CoRR},
  volume    = {abs/1402.2394},
  year      = {2014},
  ee        = {http://arxiv.org/abs/1402.2394},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}@incollection{bohlouli_towards_2013,
  title = {Towards an integrated platform for big data analysis},
  url = {http://link.springer.com.ezproxy.lib.monash.edu.au/chapter/10.1007/978-3-642-34471-8_4},
  urldate = {2014-08-25},
  booktitle = {Integration of Practice-Oriented Knowledge Technology: Trends and Prospectives},
  publisher = {Springer},
  author = {Bohlouli, Mahdi and Schulz, Frank and Angelis, Lefteris and Pahor, David and Brandic, Ivona and Atlan, David and Tate, Rosemary},
  year = {2013},
  pages = {47--56}
}
@misc{web:synchrotron,
  title = {Australian {S}ynchrotron},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{https://www.synchrotron.org.au}}}
}

@misc{web:LHC,
  title = {The {L}arge {H}adron {C}ollider | {CERN}},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{http://home.web.cern.ch/topics/large-hadron-collider}}}
}

@misc{web:Amazon,
  title = {Amazon.com: {O}nline {S}hopping for {E}lectronics, {A}pparel, {C}omputers, {B}ooks, {DVD}s \& more},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{http://www.amazon.com}}}
}

@misc{web:SparkStreaming,
  title = {Spark {S}treaming | {A}pache {S}park},
  year = {2014},
  howpublished = {\mbox{\url{https://spark.apache.org/streaming/}}}
}

@misc{web:UCBerkelyAMCLab,
  title = {AMPLab - {UC} {B}erkeley | {A}lgorithms, {M}achines and {P}eople {L}ab},
  year = {2014},
  howpublished = {\mbox{\url{https://amplab.cs.berkeley.edu}}}
}

@misc{web:Spark,
  title = {Apache {S}park\texttrademark -- {L}ightning-{F}ast {C}luster {C}omputing},
  year = {2014},
  howpublished = {\mbox{\url{https://spark.apache.org}}}
}

@misc{web:Nectar,
  title = {home | {NeCTAR}},
  year = {2014},
  month = {August},
  howpublished = {\mbox{\url{http://www.nectar.org.au}}}
}

@inproceedings{klimt2004introducing,
  title={Introducing the Enron Corpus.},
  author={Klimt, Bryan and Yang, Yiming},
  booktitle={CEAS},
  year={2004}
}


@inproceedings{sinnott_towards_2011,
  title = {Towards an e-infrastructure for urban research across Australia},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6123291},
  urldate = {2014-08-30},
  booktitle = {E-Science (e-Science), 2011 {IEEE} 7th International Conference on},
  publisher = {{IEEE}},
  author = {Sinnott, Richard O. and Galang, Gerson and Tomko, Martin and Stimson, Robert},
  year = {2011},
  pages = {295--302},
  file = {[PDF] from unimelb.edu.au:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/5HT2S9FW/Sinnott et al. - 2011 - Towards an e-infrastructure for urban research acr.pdf:application/pdf;Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/TU6W5AK5/login.html:text/html}
}

@book{marz2013principles,
  added-at = {2013-08-23T14:45:17.000+0200},
  address = {[S.l.]},
  author = {Marz, Nathan},
  biburl = {http://www.bibsonomy.org/bibtex/20dc290e810c709342f645179a9098cba/becker},
  description = {Big Data: Principles and Best Practices of Scalable Realtime Data Systems: Amazon.de: Nathan Marz, James Warren: Englische Bücher},
  interhash = {64a1336f5e196af365ef409e9ace3fa3},
  intrahash = {0dc290e810c709342f645179a9098cba},
  isbn = {1617290343 9781617290343},
  keywords = {big data lambda principles s:2013-08-23_sensorplatforms},
  publisher = {O'Reilly Media},
  refid = {810318817},
  timestamp = {2013-08-23T14:45:17.000+0200},
  title = {Big data : principles and best practices of scalable realtime data systems},
  url = {http://www.amazon.de/Big-Data-Principles-Practices-Scalable/dp/1617290343},
  year = 2013
}


@article{bifet_mining_2013,
  title = {Mining big data in real time},
  volume = {37},
  issn = {03505596},
  url = {http://go.galegroup.com/ps/i.do?id=GALE%7CA329730435&v=2.1&u=monash&it=r&p=AONE&sw=w&asid=43dd70afff364e9b2d73c1537dfe198a},
  language = {English},
  number = {1},
  urldate = {2014-08-11},
  journal = {Informatica},
  author = {Bifet, Albert},
  month = mar,
  year = {2013},
  keywords = {big data, Data mining},
  pages = {15+}
}
@article{dean_mapreduce:_2008,
  title = {{MapReduce}: Simplified Data Processing on Large Clusters},
  volume = {51},
  issn = {0001-0782},
  shorttitle = {{MapReduce}},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/1327452.1327492},
  doi = {10.1145/1327452.1327492},
  abstract = {{MapReduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct {MapReduce} programs have been implemented internally at Google over the past four years, and an average of one hundred thousand {MapReduce} jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
  number = {1},
  urldate = {2014-08-31},
  journal = {Commun. {ACM}},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  month = jan,
  year = {2008},
  pages = {107--113}
}


@inproceedings{shvachko2010hadoop,
  title={The hadoop distributed file system},
  author={Shvachko, Konstantin and Kuang, Hairong and Radia, Sanjay and Chansler, Robert},
  booktitle={Mass Storage Systems and Technologies (MSST), 2010 IEEE 26th Symposium on},
  pages={1--10},
  year={2010},
  organization={IEEE}
}

@inproceedings{zaharia2010spark,
  title={Spark: cluster computing with working sets},
  author={Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J and Shenker, Scott and Stoica, Ion},
  booktitle={Proceedings of the 2nd USENIX conference on Hot topics in cloud computing},
  pages={10--10},
  year={2010}
}

@article{khetrapal2006hbase,
  title={HBase and Hypertable for large scale distributed storage systems},
  author={Khetrapal, Ankur and Ganesh, Vinay},
  journal={Dept. of Computer Science, Purdue University},
  year={2006}
}

@inproceedings{toshniwal2014storm,
  title={Storm@ twitter},
  author={Toshniwal, Ankit and Taneja, Siddarth and Shukla, Amit and Ramasamy, Karthik and Patel, Jignesh M and Kulkarni, Sanjeev and Jackson, Jason and Gade, Krishna and Fu, Maosong and Donham, Jake and others},
  booktitle={Proceedings of the 2014 ACM SIGMOD international conference on Management of data},
  pages={147--156},
  year={2014},
  organization={ACM}
}

@inproceedings{thusoo2010hive,
  title={Hive-a petabyte scale data warehouse using hadoop},
  author={Thusoo, Ashish and Sarma, Joydeep Sen and Jain, Namit and Shao, Zheng and Chakka, Prasad and Zhang, Ning and Antony, Suresh and Liu, Hao and Murthy, Raghotham},
  booktitle={Data Engineering (ICDE), 2010 IEEE 26th International Conference on},
  pages={996--1005},
  year={2010},
  organization={IEEE}
}
@article{thusoo2009hive,
  title={Hive: a warehousing solution over a map-reduce framework},
  author={Thusoo, Ashish and Sarma, Joydeep Sen and Jain, Namit and Shao, Zheng and Chakka, Prasad and Anthony, Suresh and Liu, Hao and Wyckoff, Pete and Murthy, Raghotham},
  journal={Proceedings of the VLDB Endowment},
  volume={2},
  number={2},
  pages={1626--1629},
  year={2009},
  publisher={VLDB Endowment}
}
@article{kamburugamuve_survey_2014,
  title = {Survey of Distributed Stream Processing for Large Stream Sources},
  author = {Kamburugamuve, Supun and Fox, Geoffrey and Leake, David and Qiu, Judy},
  year = {2014}
}
@book{islam_cloud_2014,
  title = {A Cloud Based Platform for Big Data Science},
  url = {http://www.diva-portal.org/smash/record.jsf?pid=diva2:690525},
  abstract = {With the advent of cloud computing, resizable scalable infrastructures for data processing is now available to everyone. Software platforms and frameworks that support data intensive distributed ap ...},
  language = {eng},
  urldate = {2014-08-31},
  author = {Islam, Md Zahidul},
  year = {2014},
  note = {With the advent of cloud computing, resizable scalable infrastructures for data processing is now available to everyone. Software platforms and frameworks that support data intensive distributed ap ...},
  keywords = {Programvaruteknik, Software Engineering},
  file = {Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/J7Q6THMQ/record.html:text/html}
}
@article{DBLP:journals/corr/XinCDGFS14,
  author    = {Reynold S. Xin and
               Daniel Crankshaw and
               Ankur Dave and
               Joseph E. Gonzalez and
               Michael J. Franklin and
               Ion Stoica},
  title     = {GraphX: Unifying Data-Parallel and Graph-Parallel Analytics},
  journal   = {CoRR},
  volume    = {abs/1402.2394},
  year      = {2014},
  ee        = {http://arxiv.org/abs/1402.2394},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@misc{huynh_xinhs_2014,
  title = {Xinh's Tech Blog: Storm vs. Spark Streaming: Side-by-side comparison},
  shorttitle = {Xinh's Tech Blog},
  url = {http://xinhstechblog.blogspot.com.au/2014/06/storm-vs-spark-streaming-side-by-side.html},
  urldate = {2014-08-25},
  journal = {Xinh's Tech Blog},
  author = {Huynh, Xinh},
  month = jun,
  year = {2014},
  keywords = {big data, side-by-side comparison, Spark, Spark streaming, Storm, streaming data, stream processing},
  file = {Blogspot Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/U23QVXSV/Huynh - 2014 - Xinh's Tech Blog Storm vs. Spark Streaming Side-.html:text/html}
}

@inproceedings{dave_mining_2003,
  address = {New York, {NY}, {USA}},
  series = {{WWW} '03},
  title = {Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews},
  isbn = {1-58113-680-3},
  shorttitle = {Mining the Peanut Gallery},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/775152.775226},
  doi = {10.1145/775152.775226},
  urldate = {2014-09-07},
  booktitle = {Proceedings of the 12th International Conference on World Wide Web},
  publisher = {{ACM}},
  author = {Dave, Kushal and Lawrence, Steve and Pennock, David M.},
  year = {2003},
  keywords = {document classification, opinion mining},
  pages = {519--528}
}

@article{xin_graphx:_2014,
  title = {{GraphX}: Unifying Data-Parallel and Graph-Parallel Analytics},
  shorttitle = {{GraphX}},
  url = {http://arxiv.org/abs/1402.2394},
  abstract = {From social networks to language modeling, the growing scale and importance of graph data has driven the development of numerous new graph-parallel systems (e.g., Pregel, {GraphLab}). By restricting the computation that can be expressed and introducing new techniques to partition and distribute the graph, these systems can efficiently execute iterative graph algorithms orders of magnitude faster than more general data-parallel systems. However, the same restrictions that enable the performance gains also make it difficult to express many of the important stages in a typical graph-analytics pipeline: constructing the graph, modifying its structure, or expressing computation that spans multiple graphs. As a consequence, existing graph analytics pipelines compose graph-parallel and data-parallel systems using external storage systems, leading to extensive data movement and complicated programming model. To address these challenges we introduce {GraphX}, a distributed graph computation framework that unifies graph-parallel and data-parallel computation. {GraphX} provides a small, core set of graph-parallel operators expressive enough to implement the Pregel and {PowerGraph} abstractions, yet simple enough to be cast in relational algebra. {GraphX} uses a collection of query optimization techniques such as automatic join rewrites to efficiently implement these graph-parallel operators. We evaluate {GraphX} on real-world graphs and workloads and demonstrate that {GraphX} achieves comparable performance as specialized graph computation systems, while outperforming them in end-to-end graph pipelines. Moreover, {GraphX} achieves a balance between expressiveness, performance, and ease of use.},
  urldate = {2014-09-01},
  journal = {{arXiv}:1402.2394 [cs]},
  author = {Xin, Reynold S. and Crankshaw, Daniel and Dave, Ankur and Gonzalez, Joseph E. and Franklin, Michael J. and Stoica, Ion},
  month = feb,
  year = {2014},
  note = {{arXiv}: 1402.2394},
  keywords = {Computer Science - Databases},
  file = {arXiv\:1402.2394 PDF:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/4EBKWRIP/Xin et al. - 2014 - GraphX Unifying Data-Parallel and Graph-Parallel .pdf:application/pdf;arXiv.org Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/HNUM9UTB/1402.html:text/html}
}

@inproceedings{gruenheid2011query,
  title={Query optimization using column statistics in hive},
  author={Gruenheid, Anja and Omiecinski, Edward and Mark, Leo},
  booktitle={Proceedings of the 15th Symposium on International Database Engineering \& Applications},
  pages={97--105},
  year={2011},
  organization={ACM}
}

@inproceedings{pang_sentimental_2004,
  address = {Stroudsburg, {PA}, {USA}},
  series = {{ACL} '04},
  title = {A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts},
  shorttitle = {A Sentimental Education},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.3115/1218955.1218990},
  doi = {10.3115/1218955.1218990},
  urldate = {2014-09-07},
  booktitle = {Proceedings of the 42Nd Annual Meeting on Association for Computational Linguistics},
  publisher = {Association for Computational Linguistics},
  author = {Pang, Bo and Lee, Lillian},
  year = {2004}
}

@book{islam_cloud_2014,
  title = {A Cloud Based Platform for Big Data Science},
  url = {http://www.diva-portal.org/smash/record.jsf?pid=diva2:690525},
  abstract = {With the advent of cloud computing, resizable scalable infrastructures for data processing is now available to everyone. Software platforms and frameworks that support data intensive distributed ap ...},
  language = {eng},
  urldate = {2014-08-31},
  author = {Islam, Md Zahidul},
  year = {2014},
  note = {With the advent of cloud computing, resizable scalable infrastructures for data processing is now available to everyone. Software platforms and frameworks that support data intensive distributed ap ...},
  keywords = {Programvaruteknik, Software Engineering},
  file = {Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/J7Q6THMQ/record.html:text/html}
}

@inproceedings{wilson_recognizing_2005,
  address = {Stroudsburg, {PA}, {USA}},
  series = {{HLT} '05},
  title = {Recognizing Contextual Polarity in Phrase-level Sentiment Analysis},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.3115/1220575.1220619},
  doi = {10.3115/1220575.1220619},
  abstract = {This paper presents a new approach to phrase-level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions. With this approach, the system is able to automatically identify the contextual polarity for a large subset of sentiment expressions, achieving results that are significantly better than baseline.},
  urldate = {2014-09-07},
  booktitle = {Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  author = {Wilson, Theresa and Wiebe, Janyce and Hoffmann, Paul},
  year = {2005},
  pages = {347--354}
}

@article{stonebraker_8_2005,
  title = {The 8 requirements of real-time stream processing},
  volume = {34},
  url = {http://dl.acm.org.ezproxy.lib.monash.edu.au/citation.cfm?id=1107504},
  number = {4},
  urldate = {2014-09-21},
  journal = {{ACM} {SIGMOD} Record},
  author = {Stonebraker, Michael and Çetintemel, Uǧur and Zdonik, Stan},
  year = {2005},
  pages = {42--47},
  file = {Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/9CH66XUG/login.html:text/html}
}

@incollection{bohlouli_towards_2013,
  title = {Towards an integrated platform for big data analysis},
  url = {http://link.springer.com.ezproxy.lib.monash.edu.au/chapter/10.1007/978-3-642-34471-8_4},
  urldate = {2014-08-25},
  booktitle = {Integration of Practice-Oriented Knowledge Technology: Trends and Prospectives},
  publisher = {Springer},
  author = {Bohlouli, Mahdi and Schulz, Frank and Angelis, Lefteris and Pahor, David and Brandic, Ivona and Atlan, David and Tate, Rosemary},
  year = {2013},
  pages = {47--56}
}

@inproceedings{cherniack_scalable_2003,
  title = {Scalable Distributed Stream Processing.},
  volume = {3},
  url = {http://www.eecs.harvard.edu/~mdw/course/cs260r/papers/aurora-cidr03.pdf},
  urldate = {2014-09-21},
  booktitle = {{CIDR}},
  author = {Cherniack, Mitch and Balakrishnan, Hari and Balazinska, Magdalena and Carney, Donald and Cetintemel, Ugur and Xing, Ying and Zdonik, Stanley B.},
  year = {2003},
  pages = {257--268},
  file = {[PDF] from harvard.edu:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/G9TXTX2G/Cherniack et al. - 2003 - Scalable Distributed Stream Processing..pdf:application/pdf}
}

@inproceedings{begoli_short_2012,
  title = {A short survey on the state of the art in architectures and platforms for large scale data analysis and knowledge discovery from data},
  url = {http://dl.acm.org.ezproxy.lib.monash.edu.au/citation.cfm?id=2362039},
  urldate = {2014-09-21},
  booktitle = {Proceedings of the {WICSA}/{ECSA} 2012 Companion Volume},
  publisher = {{ACM}},
  author = {Begoli, Edmon},
  year = {2012},
  pages = {177--183},
  file = {[PDF] from ornl.gov:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/6NV9IK83/Begoli - 2012 - A short survey on the state of the art in architec.pdf:application/pdf;Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/ETXC4KCE/login.html:text/html}
}

@inproceedings{pang_seeing_2005,
  address = {Stroudsburg, {PA}, {USA}},
  series = {{ACL} '05},
  title = {Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales},
  shorttitle = {Seeing Stars},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.3115/1219840.1219855},
  doi = {10.3115/1219840.1219855},
  urldate = {2014-09-07},
  booktitle = {Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics},
  publisher = {Association for Computational Linguistics},
  author = {Pang, Bo and Lee, Lillian},
  year = {2005},
  pages = {115--124}
}

@inproceedings{kim_determining_2004,
  address = {Stroudsburg, {PA}, {USA}},
  series = {{COLING} '04},
  title = {Determining the Sentiment of Opinions},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.3115/1220355.1220555},
  doi = {10.3115/1220355.1220555},
  abstract = {Identifying sentiments (the affective parts of opinions) is a challenging problem. We present a system that, given a topic, automatically finds the people who hold opinions about that topic and the sentiment of each opinion. The system contains a module for determining word sentiment and another for combining sentiments within a sentence. We experiment with various models of classifying and combining sentiment at word and sentence levels, with promising results.},
  urldate = {2014-09-07},

  booktitle = {Proceedings of the 20th International Conference on Computational Linguistics},
  publisher = {Association for Computational Linguistics},
  author = {Kim, Soo-Min and Hovy, Eduard},
  year = {2004}
}

@inproceedings{sinnott_towards_2011,
  title = {Towards an e-infrastructure for urban research across Australia},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6123291},
  urldate = {2014-08-30},
  booktitle = {E-Science (e-Science), 2011 {IEEE} 7th International Conference on},
  publisher = {{IEEE}},
  author = {Sinnott, Richard O. and Galang, Gerson and Tomko, Martin and Stimson, Robert},
  year = {2011},
  pages = {295--302},
  file = {[PDF] from unimelb.edu.au:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/5HT2S9FW/Sinnott et al. - 2011 - Towards an e-infrastructure for urban research acr.pdf:application/pdf;Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/TU6W5AK5/login.html:text/html}
}

@inproceedings{pang_thumbs_2002,
  address = {Stroudsburg, {PA}, {USA}},
  series = {{EMNLP} '02},
  title = {Thumbs Up?: Sentiment Classification Using Machine Learning Techniques},
  shorttitle = {Thumbs Up?},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.3115/1118693.1118704},
  doi = {10.3115/1118693.1118704},
  abstract = {We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.},
  urldate = {2014-08-20},
  booktitle = {Proceedings of the {ACL}-02 Conference on Empirical Methods in Natural Language Processing - Volume 10},
  publisher = {Association for Computational Linguistics},
  author = {Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
  year = {2002},
  pages = {79--86}
}

@inproceedings{olston2008pig,
  title={Pig latin: a not-so-foreign language for data processing},
  author={Olston, Christopher and Reed, Benjamin and Srivastava, Utkarsh and Kumar, Ravi and Tomkins, Andrew},
  booktitle={Proceedings of the 2008 ACM SIGMOD international conference on Management of data},
  pages={1099--1110},
  year={2008},
  organization={ACM}
}

@article{gates2009building,
  title={Building a high-level dataflow system on top of {M}ap-{R}educe: the {P}ig experience},
  author={Gates, Alan F and Natkovich, Olga and Chopra, Shubham and Kamath, Pradeep and Narayanamurthy, Shravan M and Olston, Christopher and Reed, Benjamin and Srinivasan, Santhosh and Srivastava, Utkarsh},
  journal={Proceedings of the VLDB Endowment},
  volume={2},
  number={2},
  pages={1414--1425},
  year={2009},
  publisher={VLDB Endowment}
}

@article{dean_mapreduce:_2008,
  title = {{MapReduce}: Simplified Data Processing on Large Clusters},
  volume = {51},
  issn = {0001-0782},
  shorttitle = {{MapReduce}},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/1327452.1327492},
  doi = {10.1145/1327452.1327492},
  abstract = {{MapReduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct {MapReduce} programs have been implemented internally at Google over the past four years, and an average of one hundred thousand {MapReduce} jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
  number = {1},
  urldate = {2014-08-31},
  journal = {Commun. {ACM}},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  month = jan,
  year = {2008},
  pages = {107--113}
}

@inproceedings{hu_mining_2004,
  address = {New York, {NY}, {USA}},
  series = {{KDD} '04},
  title = {Mining and Summarizing Customer Reviews},
  isbn = {1-58113-888-1},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/1014052.1014073},
  doi = {10.1145/1014052.1014073},
  abstract = {Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.},
  urldate = {2014-09-06},
  booktitle = {Proceedings of the Tenth {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
  publisher = {{ACM}},
  author = {Hu, Minqing and Liu, Bing},
  year = {2004},
  keywords = {reviews, sentiment classification, summarization, text mining},
  pages = {168--177}
}


@inproceedings{liu_survey_2014,
  address = {New York, {NY}, {USA}},
  series = {{IDEAS} '14},
  title = {Survey of Real-time Processing Systems for Big Data},
  isbn = {978-1-4503-2627-8},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/2628194.2628251},
  doi = {10.1145/2628194.2628251},
  abstract = {In recent years, real-time processing and analytics systems for big data--in the context of Business Intelligence ({BI})--have received a growing attention. The traditional {BI} platforms that perform regular updates on daily, weekly or monthly basis are no longer adequate to satisfy the fast-changing business environments. However, due to the nature of big data, it has become a challenge to achieve the real-time capability using the traditional technologies. The recent distributed computing technology, {MapReduce}, provides off-the-shelf high scalability that can significantly shorten the processing time for big data; Its open-source implementation such as Hadoop has become the de-facto standard for processing big data, however, Hadoop has the limitation of supporting real-time updates. The improvements in Hadoop for the real-time capability, and the other alternative real-time frameworks have been emerging in recent years. This paper presents a survey of the open source technologies that support big data processing in a real-time/near real-time fashion, including their system architectures and platforms.},
  urldate = {2014-08-25},
  booktitle = {Proceedings of the 18th International Database Engineering \&\#38; Applications Symposium},
  publisher = {{ACM}},
  author = {Liu, Xiufeng and Iftikhar, Nadeem and Xie, Xike},
  year = {2014},
  keywords = {architectures, big data, real-time, survey, systems},
  pages = {356--361}
}
@misc{web_slideshare_b,
author={Goetz, P. Taylor},
title={Apache {S}torm {V}s. {S}park {S}treaming},
howpublished={\url{http://www.slideshare.net/ptgoetz/apache-storm-vs-spark-streaming}},
journal={Slideshare.net},
year={2014}
},

@misc{web_slideshare_a,
author={Evans, Bobby and Graves, Tom},
title={Yahoo compares {S}torm and {S}park},
howpublished={\url{http://www.slideshare.net/ChicagoHUG/yahoo-compares-storm-and-spark}},
journal={Slideshare.net},
year={2014}
}

@inproceedings{turney_thumbs_2002,
  address = {Stroudsburg, {PA}, {USA}},
  series = {{ACL} '02},
  title = {Thumbs Up or Thumbs Down?: Semantic Orientation Applied to Unsupervised Classification of Reviews},
  shorttitle = {Thumbs Up or Thumbs Down?},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.3115/1073083.1073153},
  doi = {10.3115/1073083.1073153},
  urldate = {2014-09-07},
  booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
  publisher = {Association for Computational Linguistics},
  author = {Turney, Peter D.},
  year = {2002},
  pages = {417--424}
}

@article{harrison_hadoops_2012,
  title = {Hadoop's Next-Generation {YARN}},
  volume = {26},
  copyright = {Copyright Information Today, Inc. Dec 2012},
  issn = {1547-9897},
  url = {http://search.proquest.com.ezproxy.lib.monash.edu.au/docview/1265616176?accountid=12528},
  abstract = {As the undisputed pioneer of big data, Google established most of the key technologies underlying Hadoop and many of the {NoSQL} databases. The Google File System ({GFS}) allowed dusters of commodity servers to present their internal disk storage as a unified file system and inspired the Hadoop Distributed File System ({HDFS}). Google's column-oriented key value store {BigTable} influenced many {NoSQL} systems such as Apache {HBase}, Cassandra and {HyperTable}. And, of course, the Google {MapReduce} algorithm became the foundation computing model for Hadoop and was widely implemented in other {NoSQL} systems such as {MongoDB}.
{YARN} provides much more than just improved scalability, however; it treats traditional {MapReduce} as just one of the possible frameworks that can run on the cluster. {YARN}, therefore, will allow Hadoop clusters to execute non-{MapReduce} workloads. Work is underway on a number of such applications, including Spark, Storm, Giraph, and Hama.
Only the very largest Hadoop users are likely to benefit from {YARN}'s scalability improvements. For the rest of us, the ability to extend the range of Hadoop analytics is far more significant. At the end of the day, a Hadoop cluster is only as valuable as the analytic insights it can provide. By extending the range of possible analytic models, {YARN} should contribute to the long-term success of Hadoop.},
  language = {English},
  number = {4},
  urldate = {2014-08-11},
  journal = {Database Trends and Applications},
  author = {Harrison, Guy},
  month = dec,
  year = {2012},
  keywords = {Computers, Data bases, Product development, {SQL}},
  pages = {39}
}


@article{hirzel_catalog_2014,
  title = {A catalog of stream processing optimizations},
  volume = {46},
  url = {http://dl.acm.org.ezproxy.lib.monash.edu.au/citation.cfm?id=2528412},
  number = {4},
  urldate = {2014-09-21},
  journal = {{ACM} Computing Surveys ({CSUR})},
  author = {Hirzel, Martin and Soulé, Robert and Schneider, Scott and Gedik, Buğra and Grimm, Robert},
  year = {2014},
  pages = {46},
  file = {[PDF] from usi.ch:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/XRS6HHEE/Hirzel et al. - 2014 - A catalog of stream processing optimizations.pdf:application/pdf;Snapshot:/Users/poltak/Library/Application Support/Zotero/Profiles/xrhso8df.default/zotero/storage/UD7DT7H3/login.html:text/html}
}

@inproceedings{ghemawat_google_2003,
  address = {New York, {NY}, {USA}},
  series = {{SOSP} '03},
  title = {The {G}oogle {F}ile {S}ystem},
  isbn = {1-58113-757-5},
  url = {http://doi.acm.org.ezproxy.lib.monash.edu.au/10.1145/945445.945450},
  doi = {10.1145/945445.945450},
  urldate = {2014-08-31},
  booktitle = {Proceedings of the Nineteenth {ACM} Symposium on Operating Systems Principles},
  publisher = {{ACM}},
  author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
  year = {2003},
  keywords = {clustered storage, data storage, fault tolerance, scalability},
  pages = {29--43}
}

@inproceedings{yu_towards_2003,
  address = {Stroudsburg, {PA}, {USA}},
  series = {{EMNLP} '03},
  title = {Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences},
  shorttitle = {Towards Answering Opinion Questions},
  url = {http://dx.doi.org.ezproxy.lib.monash.edu.au/10.3115/1119355.1119372},
  doi = {10.3115/1119355.1119372},
  abstract = {Opinion question answering is a challenging task for natural language processing. In this paper, we discuss a necessary component for an opinion question answering system: separating opinions from fact, at both the document and sentence level. We present a Bayesian classifier for discriminating between documents with a preponderance of opinions such as editorials from regular news stories, and describe three unsupervised, statistical techniques for the significantly harder task of detecting opinions at the sentence level. We also present a first model for classifying opinion sentences as positive or negative in terms of the main perspective being expressed in the opinion. Results from a large collection of news stories and a human evaluation of 400 sentences are reported, indicating that we achieve very high performance in document classification (upwards of 97\% precision and recall), and respectable performance in detecting opinions and classifying them at the sentence level as positive, negative, or neutral (up to 91\% accuracy).},
  urldate = {2014-09-07},
  booktitle = {Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  author = {Yu, Hong and Hatzivassiloglou, Vasileios},
  year = {2003},
  pages = {129--136}
}

@inproceedings{vavilapalli2013apache,
  title={Apache {H}adoop {YARN}: {Y}et another resource negotiator},
  author={Vavilapalli, Vinod Kumar and Murthy, Arun C and Douglas, Chris and Agarwal, Sharad and Konar, Mahadev and Evans, Robert and Graves, Thomas and Lowe, Jason and Shah, Hitesh and Seth, Siddharth and others},
  booktitle={Proceedings of the 4th annual Symposium on Cloud Computing},
  pages={5},
  year={2013},
  organization={ACM}
}

@book{mayer2013big,
  title={Big Data: A Revolution that Will Transform how We Live, Work, and Think},
  author={Mayer-Sch{\"o}nberger, V. and Cukier, K.},
  isbn={9780544002692},
  lccn={2012538859},
  series={An Eamon Dolan book},
  year={2013},
  publisher={Houghton Mifflin Harcourt}
}

@article{darlin2006airfares,
  title={Airfares made easy (or easier)},
  author={Darlin, DAMON},
  journal={The New York Times},
  volume={1},
  pages={B1},
  year={2006}
}

@inproceedings{ritterman2009using,
  title={Using prediction markets and Twitter to predict a swine flu pandemic},
  author={Ritterman, Joshua and Osborne, Miles and Klein, Ewan},
  booktitle={1st international workshop on mining social media},
  volume={9},
  year={2009}
}

@misc{ibm_big_2013,
  type = {{CT}316},
  title = {Big data architecture and patterns, {P}art 1: Introduction to big data classification and architecture},
  shorttitle = {Big data architecture and patterns, Part 1},
  howpublished = {\url{http://www.ibm.com/developerworks/library/bd-archpatterns1/}},
  urldate = {2014-10-03},
  month = sep,
  year = {2013},
}
@article{wang2014bigdatabench,
  title={Bigdatabench: A big data benchmark suite from internet services},
  author={Wang, Lei and Zhan, Jianfeng and Luo, Chunjie and Zhu, Yuqing and Yang, Qiang and He, Yongqiang and Gao, Wanling and Jia, Zhen and Shi, Yingjie and Zhang, Shujie and others},
  journal={arXiv preprint arXiv:1401.1406},
  year={2014}
}
@misc{beyer2011gartner,
author={Beyer, Mark},
title={Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data},
howpublished={\url{http://www.gartner.com/newsroom/id/1731916}},
journal={Gartner.com},
year={2011}
}
@inproceedings{dong2013big,
  title={Big data integration},
  author={Dong, Xin Luna and Srivastava, Divesh},
  booktitle={Data Engineering (ICDE), 2013 IEEE 29th International Conference on},
  pages={1245--1248},
  year={2013},
  organization={IEEE}
}
@techreport{mills2012demystifying,
  title={DEMYSTIFYING BIG DATA: a practical guide to transforming the business of Government},
  author={Mills, S and Lucas, S and Irakliotis, L and Rappa, M and Carlson, T and Perlowitz, B},
  year={2012},
  institution={Technical report. http://www. ibm. com/software/data/demystifying-big-data}
}

@article{st2009examining,
  title={Examining the Information Economy: Exploring the Overlap between Professional Communication Activities and Information-Management Practices},
  author={St Amant, Kirk and Ulijn, Jan M},
  journal={Professional Communication, IEEE Transactions on},
  volume={52},
  number={3},
  pages={225--228},
  year={2009},
  publisher={IEEE}
}
@article{lievesley1993increasing,
  title={Increasing the value of data},
  author={Lievesley, Denise},
  journal={BLRD REPORTS},
  volume={6122},
  pages={205--205},
  year={1993},
  publisher={BRITISH LIBRARY BOSTON SPA}
}
@article{geczy_big_2014,
  title = {{BIG} {DATA} {CHARACTERISTICS}},
  journal = {The Macrotheme Review},
  year = {2014},
  volume = {3},
  number = {6},
  author = {Géczy, Peter},
}
@article{chen2012business,
  title={Business Intelligence and Analytics: From Big Data to Big Impact.},
  author={Chen, Hsinchun and Chiang, Roger HL and Storey, Veda C},
  journal={MIS quarterly},
  volume={36},
  number={4},
  pages={1165--1188},
  year={2012}
}
@article{watson2009tutorial,
  title={Tutorial: Business Intelligence-Past, Present, and Future},
  author={Watson, Hugh J},
  journal={Communications of the Association for Information Systems},
  volume={25},
  number={1},
  pages={39},
  year={2009}
}

@misc{storm_users,
author={Storm.apache.org,},
title={Storm Documentation},
howpublished={\url{https://storm.apache.org/documentation/Powered-By.html}},
year={2014}
}

@article{lammel2008google,
  title={Google’s MapReduce programming model—Revisited},
  author={L{\"a}mmel, Ralf},
  journal={Science of computer programming},
  volume={70},
  number={1},
  pages={1--30},
  year={2008},
  publisher={Elsevier}
}
@article{su2014changing,
  title={Changing {E}ngines in {M}idstream: A {J}ava {S}tream {C}omputational {M}odel for {B}ig {D}ata {P}rocessing},
  author={Su, Xueyuan and Swart, Garret and Goetz, Brian and Oliver, Brian and Sandoz, Paul},
  journal={Proceedings of the VLDB Endowment},
  volume={7},
  number={13},
  year={2014}
}
@inproceedings{yang2007map,
  title={Map-reduce-merge: simplified relational data processing on large clusters},
  author={Yang, Hung-chih and Dasdan, Ali and Hsiao, Ruey-Lung and Parker, D Stott},
  booktitle={Proceedings of the 2007 ACM SIGMOD international conference on Management of data},
  pages={1029--1040},
  year={2007},
  organization={ACM}
}
@article{grossman2009varieties,
  title={On the Varieties of Clouds for Data Intensive Computing.},
  author={Grossman, Robert L and Gu, Yunhong},
  journal={IEEE Data Eng. Bull.},
  volume={32},
  number={1},
  pages={44--50},
  year={2009}
}

@misc{hadoop_committers,
author={Hadoop.apache.org,},
title={Who We Are},
howpublished={\url{https://hadoop.apache.org/who.html#Hadoop+Committers}},
year={2014}
}

@article{mckusick2009gfs,
  title={{GFS}: Evolution on {F}ast-forward.},
  author={McKusick, Marshall K and Quinlan, Sean},
  journal={ACM Queue},
  volume={7},
  number={7},
  pages={10},
  year={2009}
}
@article{borthakur2007hadoop,
  title={The hadoop distributed file system: Architecture and design},
  author={Borthakur, Dhruba},
  journal={Hadoop Project Website},
  volume={11},
  pages={21},
  year={2007}
}
@misc{hadoop_users,
author={Wiki.apache.org,},
title={Powered{B}y - {H}adoop {W}iki},
howpublished={\url{https://wiki.apache.org/hadoop/PoweredBy}},
year={2014}
}
@misc{industry_bd_survey,
author={Bange, Carsten and Grosser, Timm and Janoschek, Nikolai},
title={Big Data Survey Europe - Usage, technology and budgets in European best-practice companies},
howpublished={\url{http://www.pmone.com/fileadmin/user_upload/doc/study/BARC_BIG_DATA_SURVEY_EN_final.pdf}},
journal={pmOne - Business Intelligence, Performance Management and Reporting},
year={2013}
}
@inproceedings{isard2007dryad,
  title={Dryad: distributed data-parallel programs from sequential building blocks},
  author={Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
  booktitle={ACM SIGOPS Operating Systems Review},
  volume={41},
  number={3},
  pages={59--72},
  year={2007},
  organization={ACM}
}
@book{murthy2013apache,
  title={Apache Hadoop YARN: Moving Beyond MapReduce and Batch Processing with Apache Hadoop 2},
  author={Murthy, Arun and Vavilapalli, Vinod Kumar and Eadline, Doug and Markham, Jeffrey and Niemiec, Joseph},
  year={2013},
  publisher={Pearson Education}
}
@misc{web_tez,
author={Tez.apache.org},
title={Apache {T}ez – {W}elcome to {A}pache {T}ez},
howpublished={\url{http://tez.apache.org}},
year={2014}
}
@article{chun2013reef,
  title={Reef: Retainable evaluator execution framework},
  author={Chun, Byung-Gon and Condie, Tyson and Curino, Carlo and Douglas, Chris and Matusevych, Sergiy and Myers, Brandon and Narayanamurthy, Shravan and Ramakrishnan, Raghu and Rao, Sriram and Rosen, Josh and others},
  journal={Proceedings of the VLDB Endowment},
  volume={6},
  number={12},
  pages={1370--1373},
  year={2013},
  publisher={VLDB Endowment}
}
@misc{web_hortonworks_blog,
author={Evans, Bobby and Feng, Andy},
title={Storm-{YARN} {R}eleased as {O}pen {S}ource},
howpublished={\url{https://developer.yahoo.com/blogs/ydn/storm-yarn-released-open-source-143745133.html}},
journal={Yahoo Developer Network},
year={2013}
}
@techreport{zaharia2012discretized,
  title={Discretized streams: A fault-tolerant model for scalable stream processing},
  author={Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Hunter, Timothy and Shenker, Scott and Stoica, Ion},
  year={2012},
  institution={DTIC Document}
}

@misc{web_yahoo_blog,
author={Walker, Jim},
title={Streaming {IN} {H}adoop: {Y}ahoo! release {S}torm-{YARN} - {H}ortonworks},
howpublished={\url{http://hortonworks.com/blog/streaming-in-hadoop-yahoo-release-storm-yarn/}},
journal={Hortonworks},
year={2013}
}
@inproceedings{zaharia2013discretized,
  title={Discretized streams: Fault-tolerant streaming computation at scale},
  author={Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Hunter, Timothy and Shenker, Scott and Stoica, Ion},
  booktitle={Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
  pages={423--438},
  year={2013},
  organization={ACM}
}
@inproceedings{hunter2011scaling,
  title={Scaling the Mobile Millennium system in the cloud},
  author={Hunter, Timothy and Moldovan, Teodor and Zaharia, Matei and Merzgui, Samy and Ma, Justin and Franklin, Michael J and Abbeel, Pieter and Bayen, Alexandre M},
  booktitle={Proceedings of the 2nd ACM Symposium on Cloud Computing},
  pages={28},
  year={2011},
  organization={ACM}
}
@inproceedings{zaharia2012fast,
  title={Fast and interactive analytics over Hadoop data with Spark},
  author={Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur and Ma, Justin and Mccauley, Murphy and Franklin, M and Shenker, Scott and Stoica, Ion},
  year={2012},
  organization={USENIX}
}
@misc{web_spark_conviva,
author={Joseph, Dilip},
title={Using {S}park and {H}ive to process {B}ig{D}ata at {C}onviva},
howpublished={\url{http://www.conviva.com/using-spark-and-hive-to-process-bigdata-at-conviva/}},
journal={Conviva},
year={2011}
}
@misc{web_spark_mmp,
author={Traffic.berkeley.edu,},
title={History of the {P}roject | {M}obile {M}illennium},
howpublished={\url{http://traffic.berkeley.edu/project}},
year={2014}
}
@misc{web_samza,
author={Samza.incubator.apache.org,},
title={Samza},
howpublished={\url{https://samza.incubator.apache.org/}},
year={2014}
},

@misc{web_storm,
author={Storm.apache.org,},
title={Storm, distributed and fault-tolerant realtime computation},
howpublished={\url{https://storm.apache.org/}},
year={2014}
},

@misc{web_storm_yarn,
author={GitHub},
title={yahoo/storm-yarn},
howpublished={\url{https://github.com/yahoo/storm-yarn}},
year={2014}
}
@inproceedings{kreps2011kafka,
  title={Kafka: A distributed messaging system for log processing},
  author={Kreps, Jay and Narkhede, Neha and Rao, Jun and others},
  booktitle={Proceedings of the NetDB},
  year={2011}
}

@article{bockermann2014survey,
  title={A Survey of the Stream Processing Landscape},
  author={Bockermann, Christian},
  year={2014}
}

@inproceedings{darby2003development,
  title={The development of an instrumented wagon for continuously monitoring track condition},
  author={Darby, M and Alvarez, E and McLeod, J and Tew, G and Crew, G},
  booktitle={AusRAIL PLUS 2003, 17-19 November 2003, Sydney, NSW, Australia},
  year={2003}
}

@inproceedings{darby2005track,
  title={Track condition monitoring: the next generation},
  author={Darby, Michael and Alvarez, Eugenio and McLeod, John and Tew, Graham and Crew, Gregory and others},
  booktitle={Proceedings of 9th International Heavy Haul Association Conference},
  volume={1},
  pages={1--1},
  year={2005}
}

@inproceedings{thomas2012taking,
  title={Taking the guesswork out of speed restriction},
  author={Thomas, Simon and Hardie, Glenn and Thompson, Cameron},
  booktitle={CORE 2012: Global Perspectives; Conference on railway engineering, 10-12 September 2012, Brisbane, Australia},
  pages={707},
  year={2012},
  organization={Engineers Australia}
}

@inproceedings{neumeyer2010s4,
  title={S4: Distributed stream computing platform},
  author={Neumeyer, Leonardo and Robbins, Bruce and Nair, Anish and Kesari, Anand},
  booktitle={Data Mining Workshops (ICDMW), 2010 IEEE International Conference on},
  pages={170--177},
  year={2010},
  organization={IEEE}
}
@inproceedings{hunt2010zookeeper,
  title={ZooKeeper: Wait-free Coordination for Internet-scale Systems.},
  author={Hunt, Patrick and Konar, Mahadev and Junqueira, Flavio Paiva and Reed, Benjamin},
  booktitle={USENIX Annual Technical Conference},
  volume={8},
  pages={9},
  year={2010}
}

@misc{web:monash_irt,
author = {},
title = {Institute of Railway Technology},
howpublished = {\url{https://platforms.monash.edu/irt/}},
month = {March},
year = {2014},
note = {(Visited on 2015-05-09)}
}
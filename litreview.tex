%!TEX root = thesis.tex
% Start of content
\section{Literature Review}
\label{sec:litrev}

To lay the ground work and context of this research project, this chapter goes into detail on existing
research and work done in the areas of big data processing. Both more traditional batch processing of big
data will be looked at, along with newer advances in the area of realtime stream processing. Different
technologies enabling these processes will be discussed in detail, with the main focus being placed on the
widely used open-source projects, such as those encompassed within the Hadoop ecosystem.

The realtime processing of big data is now of more great importance to both academia and industry than it has
ever been before. Advancements and progress in modern society can be directly attributed back to data and
how we deal with it. The value of data has become increasingly more apparent, and data has become a sort of
currency for the information economy~\cite{st2009examining}. Hence, those in society who realised the value of
data early hold immense power over the entire economy, and in turn society,
overall~\cite{lievesley1993increasing}. From seemingly inconsequential gains at the macro level, such as the
ability to more accurately predict the rise and fall of airline tickets~\cite{darlin2006airfares}, to those
of utmost importance for society as a whole, such as predicting and tracking the spread of the Swine Flu
Pandemic in 2009 more accurately than the United States Centers for Disease Control and Prevention
could using big data processing~\cite{ritterman2009using,mayer2013big}. It is applications of big data
processing such as these that have been recognised by academics and organisations in industry alike, with the
last decade seeing a major shift in research and development into new methods for the handling
and processing of big data.

This review will be structured in two main sections.
In~\sectref{sub:batch_data_processing}, an overview and history for the existing major open-source batch
processing systems for big data will be given. This will mostly surround the projects which fall under the
umbrella of the Hadoop ecosystem. In~\sectref{sub:realtime_data_processing}, the current state of realtime
data processing systems for big data will be discussed, including examples of the most widely used open-source
data stream processing systems (DSPS). Comparisons will be drawn between the DSPS technologies and outlined
in how they differ. Further discussion and analysis will be given in~\sectref{sub:processing_conclusion},
including identifying the gaps in existing literature to which this research project aims to fill,
before concluding in~\sectref{sec:conclusion}.

% section introduction (end)


\subsection{Big data processing background} % (fold)
\label{sec:big_data_processing_background}

Much work has been done in the area of big data processing in the past decade, given the rise of large
scale applications and services, a lot of the time involving large numbers of users and their given data.
Data processing in general has been of large importance for many years, as no matter the business model,
some sort of data has had to be dealt with. Traditionally, this has often been handled through the use of
relational models, as introduced by Codd~\cite{codd1970relational}, through use of relational database
management systems (RDBMS), providing methods for the long term storage of
data and functions for performing queries and manipulation on that data~\cite{astrahan1976system},
such as through use of an implementation of structured query language (SQL)~\cite{chamberlin1974sequel}.

Given larger scales of data in newer projects, along with the needs to scale horizontally in terms of
parallel and distributed processing, the more traditional relational forms of data management have become
less attractive due to their complexity in terms of horizontal scaling~\cite{agrawal2011big}. Hence,
companies dealing with these large scale use cases have started to look outwards to new directions of
data management. This unattractiveness of existing technologies, in terms of scaling and parallelism,
arguably led to the need to develop something new with these objectives in mind.

Note that in this chapter, we will refer to the processing of data in realtime as simply ``realtime data
processing''. This term should be assumed to encompass the meanings that are also often represented through
use of terms such as ``data stream processing'', ``realtime stream processing'', and ``stream processing''.

\subsection{Batch data processing} % (fold)
\label{sub:batch_data_processing}

Over the last decade, the main ``go-to'' solution for any sort of processing needed on datasets falling under
the umbrella of big data has been the MapReduce programming model on top of some sort of scalable distributed
storage system~\cite{bifet_mining_2013}. From a overly simplified functional standpoint, the MapReduce
programming model essentially combines the common \textbf{Map} and \textbf{Reduce} functions (among others),
often found in the standard libraries of many functional programming languages, such as
Haskell~\cite{lammel2008google}, Clojure~\cite{hickey2008clojure}, or even Java 8~\cite{su2014changing}, to
apply a specified type of processing in a highly parallelised and distributed fashion~\cite{yang2007map}.

The MapReduce data processing model specialises in batch mode processing on data which is already available.
Batch data processing can be thought of where data needed to be processed is first queued up in ``batches''
before processing then begins on those batches. Once ready, those batches get fed into the processing system
and handled accordingly~\cite{condie2010online}.

\subsubsection{MapReduce and GFS} % (fold)
\label{ssub:mapreduce_and_gfs}

Dean and Ghemawat, in~\cite{dean_mapreduce:_2008}, originally presented MapReduce as a technology that had been
developed internally at Google, Inc.\ to be an abstraction to simplify the various computations that engineers were
trying to perform on their large datasets. The implementations of these computations, while not complicated functions
themselves, were obscured by the fact of having to manually parallelise the computations, distribute the data, and
handle faults all in an effective manner. The MapReduce model then enabled these computations to be expressed in a
simple, high-level manner without the programmer needing to worry about optimising for available resources. Furthermore,
the MapReduce abstraction provided high scalability to differently sized clusters.

As previously stated, the MapReduce programming model is generally used on top of some sort of distributed storage
system. In the previous case at Google, Inc., in the original MapReduce implementation, it was implemented on top of
their own proprietary distributed file system, known as Google File System (GFS). Ghemawat et al.,
in~\cite{ghemawat_google_2003}, define GFS to be a ``scalable distributed file system for large distributed data-intensive
applications'', noting that can be run on ``inexpensive commodity hardware''. Note that GFS was designed and in-use
at Google, Inc.\ years before they managed to develop their MapReduce abstraction, and the original paper on MapReduce
from Dean and Ghemawat state that GFS was used to manage data and store data from MapReduce~\cite{dean_mapreduce:_2008}.
Furthermore, McKusick and Quinlan, in~\cite{mckusick2009gfs}, state that, as of 2009, the majority of Google's data
relating to their many web-oriented applications rely on GFS.

% subsubsection mapreduce_and_gfs (end)


\subsubsection{Hadoop MapReduce and HDFS} % (fold)
\label{ssub:hadoop_mapreduce_and_hdfs}

While MapReduce paired with GFS proved to be very successful solution for big data processing at Google, Inc., and
there was notable research published on the technology, it was proprietary in-house software unique to Google, and
availability elsewhere was often not an option~\cite{grossman2009varieties}. Hence, the open-source software community
responded in turn with their own implementation of MapReduce and a distributed file system analogous to GFS, known as the
Hadoop Distributed File System (HDFS). Both of these projects, along with others to date, make up the Apache Hadoop
big data ecosystem~\footnote{https://hadoop.apache.org}. The Apache Hadoop ecosystem, being a top level Apache Software
Foundation open source project, has been developed by a number of joint contributors from organisations and institutions
such as Yahoo!, Inc., Intel, IBM, UC Berkeley, among others~\cite{hadoop_committers}.

While Hadoop's MapReduce implementation very much was designed to be a functional replacements for Google's MapReduce,
HDFS is an entirely separate project in its own right. In the original paper from Yahoo!~\cite{shvachko2010hadoop},
Inc., Shvachko et al.\ present HDFS as ``the file system component of Hadoop'' with the intention of being similar to
the UNIX file system, however they also state that ``faithfulness to standards was sacrificed in favour of improved
performance''.

While HDFS was designed with replicating GFS' functionality in mind, several low-level architectural and design decisions
were made that substantially differ to those documented in GFS. For example, in~\cite{borthakur2007hadoop}, Borthakur
documents the method HDFS uses when it comes to file deletion. Borthakur talks about how when a file is deleted in HDFS,
it essentially gets moved to a \texttt{/trash} directory, much like what happens in a lot of modern operating systems.
This \texttt{/trash} directory is then purged after a configurable amount of time, the default of which being six hours.
To contrast with this, GFS is documented to have more primitive way of managing deleted files. Ghemawat, et al.,
in~\cite{ghemawat_google_2003}, document GFS' garbage collection implementation. Instead of having a centralised
\texttt{/trash} storage, deleted files get renamed to a hidden name. The GFS master then, during a regularly scheduled
scan, will delete any of these hidden files that have remained deleted for a configurable amount of time, the default
being three days. This is by far not the only difference between the two file systems, this is simply an example of a
less low-level technical difference.

% subsubsection hadoop_mapreduce_and_hdfs (end)


\subsubsection{Pig and Hive} % (fold)
\label{ssub:pig_and_hive}

Given the popularity of Hadoop, there were several early attempts at building further abstractions on top of the
MapReduce model, which were met with a high level of success. As highlighted earlier, MapReduce was originally designed
to be a nice abstraction on top of the underlying hardware, however according to Thusoo et al., in~\cite{thusoo2009hive},
MapReduce was still too low level resulting in programmers writing programs that are ``are hard to maintain and reuse''.
Thus, Thusoo et al.\ built the Hive abstraction on top of MapReduce. Hive allows programmers to write queries in a
similarly declarative language to SQL --- known affectionately as \emph{HiveQL} --- which then get compiled down into
MapReduce jobs to run on Hadoop~\cite{thusoo2010hive}.

Another common abstraction that was developed prior to Hive was what is known simply as Pig. Like Hive, Pig attempts to
be a further higher level abstraction on top of MapReduce, which ultimately compiles down into MapReduce jobs, although
what differentiates it from Hive is that instead of being a solely declarative SQL-like language, it is more of a mix of
procedural programming languages while allowing for SQL-like constraints to be specified on the data set to define the
result~\cite{olston2008pig}. Olston et al.\ describe Pig's language --- known as \emph{Pig Latin} --- to be what they
define as a ``dataflow language'', rather than a strictly procedural or declarative language.

Furthermore, note that Pig and Hive, being high level abstractions on top of MapReduce, also enable many of their own
optimisations to be applied to the underlying MapReduce jobs during the compilation
stage~\cite{gates2009building,thusoo2010hive} as well as having the benefit of being susceptible to manual query
optimisations, familiar to programmers familiar with query optimisations from SQL~\cite{gruenheid2011query}.

% subsubsection pig_and_hive (end)

% subsection batch_data_processing (end)


\subsection{Realtime data processing} % (fold)
\label{sub:realtime_data_processing}

With HDFS being an open source project with a large range of users~\cite{hadoop_users} and code
contributors~\cite{hadoop_committers}, it has grown as a project in the last few years for uses beyond what it was
originally intended for; a backend storage system for Hadoop MapReduce. HDFS is now not only used with Hadoop's
MapReduce but also with a variety of other technologies, a lot of which run as a part of the Hadoop ecosystem.
Big data processing has moved on from the more ``traditional'' method of processing, involving MapReduce jobs, which
were most suitable for batch processing of data, to those methods which specialise in the realtime processing of data.
The main difference of which is that rather than waiting for all the data before processing can be started, in realtime
data processing the data can be streamed into the processing system in realtime at any time in the whole process.

Comparing batched data processing to realtime data processing, it is useful to relate back to the four V's
identified in~\sectref{sub:four_v}. Velocity of data is often inconsistent with realtime processing, while in batch mode
processing, where you are processing the data that has already arrived and is waiting in batches to be processed, the
velocity can be considered consistent. Veracity of data is often not expected to be as consistent in realtime, as
sometimes there might be times where data does not arrive or only certain parts of the data arrive at certain times.
A realtime processing system, often called a data stream processing system (DSPS) in other literature, needs to be able
to deal with these timeliness issues, while a batch data processing system may expect everything that needs to be there
to be available.

\subsubsection{Hadoop YARN} % (fold)
\label{ssub:apache_hadoop_yarn_}

As previously looked at, the focus of the MapReduce model was performing distributed and highly parallel computations
on distributed batches of data. This suited a lot of the big data audience, and hence Hadoop became the dominant
method of big data processing~\cite{liu_survey_2014}. However for some more specialised applications, such as
the realtime monitoring of sensors, stock trading, and realtime web traffic analytics, the high latency between the data
arriving and actual results being generated from the computations was not satisfactory~\cite{kamburugamuve_survey_2014}.

A recent (2013) industry survey on European company use of big data technology by Bange, Grosser, and Janoschek, noted
in~\cite{industry_bd_survey}, shows that over 70\% of responders show a need for realtime processing. In that time,
there has certainly been a response from the open-source software community, responding with extensions to more
traditional batch systems, such as Hadoop, along with complete standalone DSPS solutions.

On the Hadoop front, the limitations of the MapReduce model were recognised, and a large effort was made in developing
the ``next generation'' of Hadoop so that it could be extensible and used with other programming models, not locked into
the rigidity of MapReduce. This became known officially known as YARN (Yet Another Resource Negotiator). According to
the original developers of YARN, Vavilapalli et al.\ state that YARN enables Hadoop to become more modular, decoupling
the resource management functionality of Hadoop from the programming model (traditionally, MapReduce)~\cite{vavilapalli2013apache}.
This decoupling essentially allowed for non-MapReduce technologies to be built on top of Hadoop, still interacting with the
overall ecosystem, allowing for much more flexible applications of big data processing on top of the existing robust
framework Hadoop provides.

Examples of such systems now built, or in some cases ported, to run on top of Hadoop, providing alternative processing
applications and use cases include:

\begin{itemize}
  \item Dryad, a general-purpose distributed execution system from Microsoft Research~\cite{isard2007dryad}. Dryad is
  aimed at being high level enough to make it ``easy'' for developers to write highly distributed and parallel applications.
  \item Spark, a data processing system, from researchers at UC Berkeley, that focuses on computations that reuse the same working data set over multiple
  parallel operations~\cite{zaharia2010spark}. Spark, and in particular Spark Streaming, will be looked at further in~\sectref{ssub:spark_streaming}.
  \item Storm, a realtime stream processing system~\cite[p.\ 244]{murthy2013apache}. Performs specified processing on an
  incoming stream of data indefinitely, until stopped. Storm will be looked at further in~\sectref{ssub:storm}.
  \item Tez, an extensible framework which allows for the building of batch and interactive Hadoop applications~\cite{web_tez}.
  \item REEF, a YARN-based runtime environment framework~\cite{chun2013reef}. REEF is essentially a further abstraction
  on top of YARN, with the intention of making a unified big data application server.
  \item Samza, a relatively new realtime data processing framework from LinkedIn. Discussed further in~\sectref{ssub:samza}.
\end{itemize}

These are just some of the more popular examples of applications built to interact with the Hadoop ecosystem via YARN.

% subsubsection apache_hadoop_yarn_ (end)


\subsubsection{Storm} % (fold)
\label{ssub:storm}

One very notable DSPS technology developed independently of Hadoop, and that is gaining immense popularity and growth in its
user base, is the Storm project. Storm was originally developed by a team of engineers lead by Nathan Marz at
BackType~\cite{web_storm}. BackType has since been acquired by Twitter, Inc.\ where development has
continued. Toshniwal et al.~\cite{toshniwal2014storm}\ describe Storm, in the context of its use at Twitter, as ``a
realtime distributed stream data processing engine'' that ``powers the real-time stream data management tasks that are
crucial to provide Twitter services''~\cite[p.\ 147]{toshniwal2014storm}. Since the project's inception, Storm has seen mass
adoption in industry, including among some of the biggest names, such as Twitter, Yahoo!, Alibaba, and
Baidu~\cite{storm_users}.

While Storm does not run on top of YARN, there is currently a large effort from engineers at Yahoo!, Inc.\ being put
into a YARN port for Storm, named ``storm-yarn''~\cite{web_storm_yarn}. This YARN port will
allow applications written for Storm to take advantage of the resources managed in a Hadoop cluster by YARN. While still
in early stages of development, ``storm-yarn'' has begun to gain attention in the developer community, through focus from
channels such as the Yahoo Developer Network~\cite{web_yahoo_blog} and Hortonworks~\cite{web_hortonworks_blog}.

% subsubsection storm (end)


\subsubsection{Spark Streaming} % (fold)
\label{ssub:spark_streaming}

Spark is another popular big data distributed processing framework, offering of both realtime data processing
and more traditional batch mode processing, running on top of YARN~\cite{zaharia2010spark}. Spark was developed at UC
Berkeley, and is notable for its novel approach to in-memory computation, through Spark's main data abstraction which is
termed a \emph{resilient distributed dataset} (RDD). An RDD is a set of data on which computations will be performed,
which can be specified to be cached in the memory across multiple machines. What this then allows is multiple distributed
operations being performed on this same dataset in parallel. A further benefit from the design of Spark is the reduce of
overhead from IO operations. Spark is designed with highly iterative computations in-mind, where the intermediate data
at each iteration stays in memory without being written and read to the underlying storage system (\eg{}HDFS).

As stated earlier, Spark allows the processing of data in realtime and batch mode. Originally, Spark was released as a
project that simply focused on batch processing, however after the need for realtime processing became apparent, an
extension project, Spark Streaming, was initiated. Spark Streaming uses a different programming model that involves what
is labelled as ``D-Streams'' (discretised streams), which essentially lets a series of deterministic batch computations
be treated as a realtime data stream~\cite{zaharia2012discretized}. The D-Stream model is specific to the Spark Streaming
system --- the original batch mode Spark system continues to use the previously mentioned RDD abstraction --- and the
creators claim performance improvements of being $2-5\times$ faster than  other realtime data processing systems, such as S4
and Storm~\cite{zaharia2013discretized}. However, this has since been disputed~\cite{web_slideshare_b}.

Both Spark and Spark Streaming have started to gain notable usage in both industry and research projects in academia in
the last few years. Online video distribution company, Conviva Inc., report to be using Spark for the processing of
analytics reports, such as viewer geographical distribution reports~\cite{web_spark_conviva,zaharia2012fast}. The Mobile
Millennium project at UC Berkeley~\cite{web_spark_mmp}, a traffic monitoring system that uses GPS through users'
cellular phones for traffic monitoring in the San Francisco Bay Area, has been using Spark for scaling the main
algorithm in use for the project: an expectation maximisation (EM) algorithm that has been parallelised by being run on
Spark~\cite{hunter2011scaling}.

% subsubsection spark_streaming (end)

\subsubsection{Samza} % (fold)
\label{ssub:samza}

Samza is a relatively new realtime big data processing framework originally developed at LinkedIn, which has since been
open-sourced at the Apache Software Foundation~\cite{web_samza}. Samza offers much similar functionality to that of
Storm, however instead the running of Samza is highly coupled with the Kafka message broker, which handles the input
and output of data streams. Essentially, Kafka is a highly distributed messaging system that focusses on the handling
of log data~\cite{kreps2011kafka}, integrating with the Hadoop ecosystem.

While Samza is lacking in maturity and adoption rates, as compared to projects such as Storm, it is built on mature
components, such as YARN and Kafka, and thus a lot of crucial features are offloaded onto these platforms. For example,
the archiving of data, stream persistence, and imperfection handling is offloaded to Kafka~\cite{bockermann2014survey}.
Likewise, YARN is used for ensuring fault tolerance through the handling of restarting machines that have failed in a
cluster~\cite{bockermann2014survey}.

% subsubsection samza (end)

\subsubsection{S4} % (fold)
\label{ssub:s4}

S4 (Simple Scalable Streaming System) is another realtime big data processing framework that originated at Yahoo!, Inc.\
that has since been open-sourced~\cite{neumeyer2010s4}. It is a relatively old project compared to the before-mentioned projects,
with development becoming less of a priority in the last few years. S4 was highly influenced by the MapReduce programming
model that was discussed in~\sectref{ssub:mapreduce_and_gfs}.

Much like what was said about Samza in~\sectref{ssub:samza}, S4 attempts offload several lower level tasks to more
mature and established systems specialising in those areas. The logical architecture of S4 lays out its jobs in a
network of processing elements (PEs) which are arranged as a directed acyclic graph. Each of these PEs entail the type
of processing to be done on the data at that point in the network. Each of the PEs are assigned to a processing node, a
logical host in the cluster. The management and coordination of these processing nodes is offloaded by S4 to
ZooKeeper~\cite{kamburugamuve_survey_2014}. Much like the before-mentioned Kafka, ZooKeeper in itself is its own complex
service used as a part of many different big data infrastructures, including Samza. ZooKeeper specialises in the high-performance
coordination of distributed processes inside distributed applications~\cite{hunt2010zookeeper}.

% subsubsection s4 (end)

% subsection realtime_data_processing (end)

\subsection{Discussion and analysis} % (fold)
\label{sub:processing_conclusion}

From the previously covered literature, it is rather difficult to provide a reasonable comparison for all the different
realtime data processing projects. A lot of the claims made in original literature relating to the projects cannot be
quantified fairly, as comparisons or tests have not been carried out relating to other projects. Instead, Stonebraker,
\c{C}\~entintemel, and Zdonik proposed what they claim to be the 8 requirements for realtime data processing systems~\cite{stonebraker_8_2005},
which can be used to given an impartial comparison of the previously covered projects. The requirements were defined a
number of years prior to the creation of the four main realtime data processing systems that were covered (2005), however are highly
cited as being the defining features that the current generation of realtime data processing systems have strived to meet.
The requirements put forward by Stonebraker et al.\ are summarised as follows:

\noindent \textbf{1: Keep the data moving -} This requirement relates to the high mobility of data and importance of low
latency in the overall processing. Hence, processing should happen as data moves, rather than storing it first, then
processing what is stored.

\noindent \textbf{2: SQL on streams -} This requirement states that a high-level SQL-like query language should be
available for performing on-the-fly queries on data streams. SQL is given as an example, however it is noted the language's
operators should be more oriented to data streams.

\noindent \textbf{3: Handle stream imperfections -} Given the high degree of imperfections in data streams, including
factors such as missing and out-of-order data, this requirement states that processing systems need to be able to handle
these issues. Simply waiting for all data to arrive if some is missing is not acceptable.

\noindent \textbf{4: Generate predictable outcomes -} This requirement relates to the determinism associated with the
outcomes of specified processes to be applied to data. A realtime processing system should have predictable and repeatable
outcomes. Note that this requirement is rather hard to satisfy as in practice data streams are, by character, rather
unpredictable. However, the operations performed on given data are required to be predictable.

\noindent \textbf{5: Integrate stored and streamed data -} This requirement states that a realtime processing system
should provide the capabilities to be able to process both data that is already stored and data that is being delivered
in realtime. This should happen seamlessly and provide the same programming interface for either source of data.

\noindent \textbf{6: Guarantee data safety and availability -} This requirement states that realtime processing systems
should ensure that they have a high level of availability for processing data, and in any cases of failures, the integrity
of data should remain consistent.

\noindent \textbf{7: Partition and scale applications automatically -} This requirement states that the partitioning of
and processing of data should be performed transparently and automatically over the hardware on which it is running on.
It should also scale to more different levels of hardware without user intervention.

\noindent \textbf{8: Process and respond instantaneously -} This requirement relates to delivering highly responsive
feedback to end-users, even for high-volume applications.

The previously covered literature has been used to determine whether or not the before-mentioned realtime data processing
systems adhere to these requirements. The outcome of this is shown in~\tabref{tab:processing_systems_compare}.

Note that in~\tabref{tab:processing_systems_compare}, those cells with ``N/A'' as the value simply mean that the literature
is inconclusive on whether or not they adhere to the particular requirement. Further investigation is required.

\import{includes/tables/}{data_processing_compare}

% subsection conclusion (end)

% section big_data_processing_background (end)


\subsection{Conclusion} % (fold)
\label{sec:conclusion_litrev}

The choosing of appropriate realtime data processing frameworks for the processing of a given application and dataset
is an important, and often confusing, problem. Most frameworks compare themselves in terms of performance with other
frameworks, often which are disputed by members in other framework ``camps''~\cite{web_slideshare_b,web_slideshare_a}.
Hence, providing an informed recommendation based on processing requirements and the class into which the dataset
falls is a much needed and important contribution to address the gap shown to exist in current systems.

This taxonomy of realtime data processing technologies will be based off the literature relating to the realtime data
processing frameworks, as presented in~\sectref{sub:realtime_data_processing}. This taxonomy will be used, along with the
created taxonomy of data classes, to develop the previously stated processing recommendations.

This research will further the field of realtime big data processing in addressing the shown gaps, and making the
decision process far more streamlined for researchers and developers alike.

% section conclusion (end)


%!TEX root = thesis.tex
% Start of content
\chapter{Introduction}
\label{sec:intro}

Currently, as a society, we are generating very large amounts of data from a large range of different sources. These
sources include scientific experiments, such as the Australian Synchrotron~\cite{web:synchrotron} and The Large Hadron
Collider~\cite{web:LHC}, companies, such as Amazon~\cite{web:Amazon}, and also data generated by end users of products,
such as social networks. The rate of data that is being generated is constantly increasing, presenting major challenges
when it comes to the storage and processing of that data~\cite{bohlouli_towards_2013}. This is what is often referred to
now as ``Big Data''. A further big data project, that will be looked into as the basis of the project outlined in this
thesis, is the automated monitoring of railway tracks and cars by the Institute of Railway Technology at Monash University
(IRT)~\cite{web:monash_irt}.

Out of all of these data that we are faced with in such projects, often only specific parts of the data are of particular use for given
purposes. Hence, rather than attempting to store all the new data that is being generated, an increasingly popular method of
dealing with such data, in both academia and industry associated with big data, is the processing and analysis of
data in realtime as it is received. This is also known as online processing, or single pass processing, where data is
processed in real time before being discarded. Further options also exist where data is stored after processing, depending
on the specific use-case.

There are currently numerous realtime data processing systems that are in development and in production use, both in
industry and academia. Examples of these realtime data processing frameworks include the widely used Storm
project~\cite{web:Storm}, developed at BackType and Twitter, Inc., and also the up-and-coming Spark Streaming
project~\cite{web:SparkStreaming}, developed at UC Berkeley's AMPLab~\cite{web:UCBerkelyAMCLab}, both of which are
open-source projects. While there are a growing number of these projects being developed, often these projects are designed
with a particular type of processing in mind. For example, the before
mentioned Spark Streaming project, along with its mother project, Spark~\cite{web:Spark}, was originally designed for highly
parallelisable data with the use-case in mind of processing data in-memory using highly iterative machine learning
algorithms related to data analytics~\cite{liu_survey_2014}.

What is proposed in this chapter is a realtime big data processing pipeline for the aforementioned railway monitoring
system by the IRT at Monash University. This processing pipeline will allow the possibility that data is able to be
streamed in realtime from the railway, and processed according to the team's given processing requirements. Multiple
technologies exist in which this pipeline can be implemented, so a technology recommendation will be formed through
the testing and evaluation of different implementations in different technologies.

This chapter will be structured as follows:\\
A brief outline of the big data processing domain, both batch and realtime processing, will be given
in~\sectref{sec:research_context}. Furthermore, an overview of the Monash University Institute of Railway Technology's
project, upon which this project is based on, will be covered in the aforementioned section. In~\sectref{sec:objectives},
the aims of the entire project will be given, as well as more specific goals and aims relating to the sub-project
covered in this thesis. Research questions for this sub-project will be given in~\sectref{sub:research_questions}.
Finally, the structure of this overall thesis will be given in~\sectref{sub:proposed_thesis_chapter_headings}, before
concluding this chapter in~\sectref{sec:summary}.

% section introduction (end)



\section{Research Context} % (fold)
\label{sec:research_context}

\subsection{Big Data} % (fold)
\label{sub:big_data}

Big data, as explained previously, is becoming commonplace in both industry and academia. Everyday companies are finding
that they are generating large volumes of data and that their traditional relational database management system (RDMBS) solutions cannot
scale to the epic proportions needed to handle this data in an efficient and robust manner~\cite{marz2013principles}.
Hence, companies and academics alike have started looking at alternative solutions designed with the goal of handling
these massive datasets.

The most popular solution for this problem, up until recently, has been the MapReduce % TODO: Add reference to MR
 model of programming along with
some type of scalable distributed storage system~\cite{bifet_mining_2013}. The MapReduce model was started at Google,
Inc.\@ with their own proprietary implementation along with their proprietary distributed file system, known as the Google
File System (GFS)~\cite{ghemawat_google_2003}. Without going into the low-level details of MapReduce and GFS, the use of this solution at Google
allowed the company to easily handle all the data that was coming into their servers, including those related to Google Search, and perform the necessary
processing operations that was needed at the time~\cite{ghemawat_google_2003,dean_mapreduce:_2008}.

% subsection big_data (end)

\subsection{Batch Data Processing} % (fold)
\label{sub:apache hadoop}

From the success of MapReduce usage combined with GFS, at Google, the open-source community responded swiftly with the
development of the Apache Hadoop framework\footnote{https://hadoop.apache.org}. Hadoop originally offered an open-source
implementation of MapReduce and their own open-source distributed file system known as the Hadoop Distributed File System
(HDFS)~\cite{shvachko_hadoop_2010}.

Hadoop soon became the subject of mass-adoption in both industry and academia, being deployed at a fast rate.
Development of the Hadoop framework also grew at a fast rate, with new applications related to HDFS and MapReduce being
built on top of Hadoop, greatly benefiting the ecosystem as a whole. Some of these applications grew into widely adopted
systems in their own right. For example, Hadoop applications such as Apache Pig~\cite{gates2009building} and
Hive~\cite{thusoo2010hive} allow for easy querying and manipulation of data stored on HDFS, both coming with the
addition of their own query languages~\cite{olston_pig_2008}.

As further non-MapReduce model applications became of interest to the Hadoop community, Hadoop soon
developed a further abstraction on top of the underlying resources (in most cases, HDFS). The goal of this was to
facilitate the development and deployment of many different applications, varying in use-case, which could be run on the
Hadoop ecosystem, without forcing developers to fit their application into the MapReduce model. This development was
known as Apache Hadoop YARN:\@ Yet Another Resource Negotiator, which can be thought of as an operating system-like abstraction sitting
atop of the available Hadoop resources~\cite{vavilapalli_apache_2013}. The abstraction provided by YARN facilitated the
development of much more advanced, and non-MapReduce technologies which have since become widely used parts of the
Hadoop ecosystem~\cite{harrison_hadoops_2012}.

% subsection apache_hadoop (end)

\subsection{Realtime Data Processing} % (fold)
\label{sub:prop_realtime_data_processing}

One of the major limitations of Hadoop, and the MapReduce model in general, soon became obvious:\@ MapReduce was designed
with the goal of being able to process batches of data, hence, given Hadoop's dominance, batched data processing was the
focal point of the entire distributed data processing domain~\cite{kamburugamuve_survey_2014}. Essentially, batched data
processing is where data gets collected first into large enough batches before being processed all-at-once. The point of
processing in such a way is so there would be less overheads than attempting to process each individual datum as it
arrives. For a lot of use-cases this was, and still is, fine as there were no other drawbacks apart from a high level of
latency between the stages of when the data arrives and when it gets processed. However, for other applications, such as
stock trading, sensor monitoring, and web traffic processing, a more low-latency, realtime solution was
needed~\cite{kamburugamuve_survey_2014}.

Soon, many solutions, with different use-cases and design goals, were developed in the area of distributed stream
processing systems (DSPS). Given the Hadoop ecosystem that was already widely adopted, most of these DSPSs were built
upon the still new YARN layer, ensuring overall compatibility with the Hadoop ecosystem, and the underlying HDFS. Some
examples of such projects include the beforementioned Apache Storm, currently being used at Twitter,
Inc.~\cite{toshniwal_stormtwitter_2014}, among many other companies. Also up-and-coming projects, such as Apache Samza
which is a recently open-sourced project, currently being used in production at LinkedIn Corporation~\cite{web:Samza}.

% subsection realtime_data_processing (end)

\subsection{Monash IRT Railway Project} % (fold)
\label{sub:monash_irt_railway_project}

The railway project that has been developed at Monash University's Institute of Railway Technology\footnote{https://platforms.monash.edu/irt/}
uses numerous sensor
technologies on certain train cars, such as the Track Geometry Recording Car (TGRC) and the Instrumented Ore Car (IOC),
to monitor railway track conditions and detect track abnormalities~\cite{darby2003development,darby2005track}.
These train cars operate in the Pilbara region of Western Australia, continuously performing round trips from a port
to a given loading point, where they are loaded with recently mined minerals and ores.

As is currently the case, data is received and processed using batch data processing technologies. Due to limited coverage
of cellular networks in the Pilbara region of Western Australia, in which the trains currently operate, sensor data from
a given trip is automatically transmitted in large batches to be received by remote servers once a train has concluded a
round trip and
arrives back in port from a loading point~\cite{thomas2012taking}. Given the current cellular network infrastructure in
the region, this is the only feasible option for transmission of data, however Monash IRT have indicated that given
future improvements in cellular network infrastructure, streaming the data back to remote servers in realtime is a likely
possibility. This leads to the potential possibility of this research project's outcomes outlined in this thesis.

The form of batch handling and processing performed on the railway data currently leads to a number of limitations and
problems. The data is currently stored in a relational database management system (RDBMS), and with the current
implementation
of the sensors, the data received is not consistently structured. In fact, the only sensor data guaranteed to be received
in each batch is geographic location and time. Due to the highly structured nature of RDBMS technology, certain work-arounds
need to be performed on the data so that it is compliant to RDBMS schemas, such as the insertions of default values in
the case of missing attributes. Furthermore, low query performance has been noted as a problem plaguing the IRT team
working with the railway data. They wish to resolve these problems by looking into non-relational models for their data
storage and processing systems.

% subsection monash_irt_railway_project (end)

% section research_context (end)



\section{Research Aim} % (fold)
\label{sec:objectives}

The main aim of the entire IRT research project is to develop a fully automated, non-relational big data pipeline to manage
the data received from railway car sensors as a part of Monash University's Institute of Railway Technology project. The
intention is to replace their current relational solution, with a non-relational big data system, offering at least the same capabilities at a larger scale and
with higher performance. The scope of this project is relatively large, and the project, or sub-project, outlined in this
thesis only covers a portion of the greater aforementioned project.

The main aim of this sub-project, outlined in this thesis, is to investigate possible solutions of dealing with the railway sensor data being
streamed and processed in realtime. Based on identified candidate solutions, a recommendation will be formed which will be
used by the IRT team to implement their required realtime processing logic.

To allow the possibility of realtime data streaming from the railway sensors, and forming a recommendation for the most
suitable solution, appropriate data stream processing system
(DSPS) technologies need to be looked at, tested, and evaluated. This makes up the core part of this sub-project's work.
These DSPS technologies need to appropriately take, or accept, the data from some specified source, \eg the sensors, apply
any realtime processing logic that is required, \eg pre-processing, then forward the data on for handling at
another source, \eg long term storage, such as HDFS.

A data filtering ``pipeline'', through which the sensor data flows, will need to be implemented in each of the candidate
DSPS technologies, which can then be used for the testing and evaluation.
By the end of this sub-project, we aim to have proof-of-concept implementations of the pipeline working on the National
eResearch Collaboration Tools and Resources (NeCTAR) cloud services~\cite{web:Nectar}, making use of the candidate DSPS
technologies, along with our overall DSPS technology recommendation for use in the IRT project.

% section objectives (end)



\section{Research Questions} % (fold)
\label{sub:research_questions}

The following research questions are the main focus points of this sub-project:

\begin{enumerate}
  \item\label{item:dsps} Which existing DSPS technologies can be used to build a data filtering pipeline for the Monash
  University IRT project?
  \item\label{item:pipeline} What criteria-based qualitative and performance-based quantitative tests can be performed
  to \textbf{recommend} a particular DSPS technology for building the pipeline?
  \item\label{item:recommendations} Can the data filtering pipeline be designed to be extensible, allowing for the
  addition of future realtime processing requirements?
\end{enumerate}

Additionally, after answering each of these preliminary research questions, we will want to properly implement the
theoretical discoveries from each stage. We do this with the goal of achieving a deployable pipeline that can be then
be used in the testing and overall evaluation stages.

% subsection research_questions (end)


\section{Thesis Structure} % (fold)
\label{sub:proposed_thesis_chapter_headings}

The proposed structure of the remainder of the thesis is as follows. Chapter 2, in~\sectref{sec:litrev}, looks at prior
research and work into the area of big data stream processing, performed both in industry and academia.
A clear overview of the DSPS technologies chosen for this project, along with the design and implementation
of the experimental systems to be used in the evaluation will be given in Chapter 3, in~\sectref{sec:implementation}.
An overview of the testing metrics, environment, results, and an overall evaluation discussion will be given in Chapter 4, in~\sectref{sec:evaluation}.
Finally, Chapter 5, in~\sectref{sec:conclusion} will conclude the thesis, highlighting the contribution made through this research project,
along with highlighting any future work that have been made apparent as the result of this project.

% subsection proposed_thesis_chapter_headings (end)


\section{Summary} % (fold)
\label{sec:summary}

This chapter has introduced the overall project, and in-turn the sub-project upon which this thesis will be based. It
has briefly described the current state of the Monash University Institute of Railway Technology's project and the current
problems that they are faced with, such as the need to deal with non-consistently structured data and low query
performance. These problems are exacerbated given the non-realtime nature of the current data, where issues with sensors
are only discovered much later after-the-fact. To overcome these issues, and to look forward into the hypothetical,
but likely, possibility of having the technological infrastructure to support realtime data processing, this research
aims to develop a realtime processing pipeline, taking the data straight from the railway sensors and perform any
needed realtime processing, and come up with a DSPS technology recommendation for the implementation of this pipeline.

This chapter also outlined a brief context of the research project and big data as a whole, the scope of this sub-project,
and this sub-project's research questions. Finally it was concluded with an overview of the entire structure of this thesis. The
following chapter will look into previous research that has been done on realtime big data processing and handling,
along with going into more detail of the railway project's needs.

% section summary (end)

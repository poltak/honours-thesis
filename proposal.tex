
% Start of content

\section{Introduction} % (fold)
\label{sec:proposal_introduction}

Currently, as a society, we are generating very large amounts of data from a large range of different sources. These
sources include scientific experiments, such as the Australian Synchrotron~\cite{web:synchrotron} and The Large Hadron
Collider~\cite{web:LHC}, companies, such as Amazon~\cite{web:Amazon}, and also data generated by end users of products,
such as social networks. The rate of data that is being generated is constantly increasing, presenting major challenges
when it comes to the storage and processing of that data~\cite{bohlouli_towards_2013}. This is what is often referred to
now as ``Big Data''. Out of all of this data we are faced with, often only specific parts of the data are of use for given
purposes. Hence, rather than attempting to store all the new data that is being generated, an increasingly popular method of
dealing with such data, in both academia and industry associated with big data, is the realtime processing and analysis of 
data as it is received.

There are currently numerous realtime data processing frameworks that are in development and in production use, both in
industry and academia. Examples of these realtime data processing frameworks include the widely used Storm
project~\cite{web:Storm}, developed at BackType and Twitter, Inc., and also the up-and-coming Spark Streaming
project~\cite{web:SparkStreaming}, developed at UC Berkeley's AMPLab~\cite{web:UCBerkelyAMCLab}, both of which are
open-source projects. While there are a growing number of these projects being developed, often these projects are designed
with a particular type of data in mind, or to facilitate a particular type of data processing. For example, the before
mentioned Spark Streaming project, along with its mother project, Spark~\cite{web:Spark}, was designed for highly
parallelisable data with the use-case in mind of processing data in-memory using highly iterative machine learning
algorithms related to data analytics~\cite{liu_survey_2014}.

Given these, occasionally ``narrow'', use-cases for existing data stream processing frameworks, challenges are faced in
supporting the variations in both data types and processing requirements for data processing applications. In this
research project, we aim to study the different characteristics of the data processing requirements based on the
different characteristics of the data types. The knowledge found of these characteristics will be compared with the
properties of existing solutions for big data processing.

What we propose in this document is an entire heterogeneous data processing pipeline that will facilitate the following
tasks, in sequence:

\begin{enumerate}
  \item Take in streams of data from various sources.
  \item Aggregate similar types of data.
  \item Process the data appropriately, depending on its type and the application.
  \item Store the results of the data processing on an appropriate storage medium.
\end{enumerate}

From this research project, we aim to produce a set of recommendations on choosing the various components of the
pipeline, along with recommendations on how the components should be interconnected. To complement this, we also aim to
produce a design template on the deployment of the pipeline in a cloud environment. This will be expanded on in further
detail in~\sectref{sec:expected_outcomes}.

This document will be structured as follows:\\ Discussion of the existing research and work done into this area will be
touched on in~\sectref{sec:research_context}. Our research questions, along with an outline of what we will be doing
will be outlined in~\sectref{sec:objectives}. The methodology used to achieve the deliverables of this project will be
discussed in~\sectref{sec:methodology}. The design of the entire research project will be shown
in~\sectref{sec:research_design}.  Finally, we will conclude with an overview, in~\sectref{sec:expected_outcomes}, of
what the expected outcomes and deliverables of this project will be.

% section introduction (end)


\newpage


\section{Research Context} % (fold)
\label{sec:research_context}

\subsection{Big data} % (fold)
\label{sub:big_data}

Big data, as explained previously, is becoming commonplace in both industry and academia. Everyday companies are finding
that they are generating too much data and that their traditional database management system (DMBS) solutions cannot
scale to the epic proportions needed to handle this data in an efficient and robust manner~\cite{marz2013principles}.
Hence, companies and academics alike have started looking at alternative solutions designed with the goal of handling
these massive datasets.

The most popular solution for this problem, up until recently, has been the MapReduce model of programming along with
some type of scalable distributed storage system~\cite{bifet_mining_2013}. The MapReduce model was started at Google,
Inc.\@ with their own proprietary implementation along with their proprietary distributed file system, known as the Google
File System (GFS). Without going into the low-level details of MapReduce and GFS, the use of this solution at Google
allowed the company to easily handle all the data that was coming into their servers, including that related to Google Search, and perform the necessary
processing operations that was needed at the time~\cite{ghemawat_google_2003}~\cite{dean_mapreduce:_2008}.

% subsection big_data (end)

\subsection{Batch data processing} % (fold)
\label{sub:apache hadoop}

From the success of MapReduce usage combined with GFS at Google, the open-source community responded swiftly with the
development of the Apache Hadoop framework. Hadoop originally offered an open-source implementation of MapReduce and
their own open-source distributed file system known as the Hadoop Distributed File System
(HDFS)~\cite{shvachko_hadoop_2010}.

Hadoop soon became the subject of mass-adoption in both industry and academia, being deployed at a fast rate.
Development of the Hadoop framework also grew at a fast rate, with new applications related to HDFS and MapReduce being
built on top of Hadoop, greatly benefiting the ecosystem as a whole. Some of these applications grew into widely adopted
systems in their own right. For example, Hadoop applications such as Apache Pig~\cite{gates_building_2009} and
Hive~\cite{thusoo_hive_2010} allow for easy querying and manipulation of data stored on HDFS, both coming with the
addition of their own ``SQL-like'' query languages~\cite{olston_pig_2008}.

Additionally, as further non-MapReduce model applications became of interest to the Hadoop community, Hadoop soon
developed a further abstraction on top of the underlying resources (in most cases, HDFS). The goal of this was to
facilitate the development and deployment of many different applications, varying in use-case, which could be run on the
Hadoop ecosystem, without forcing developers to fit their application into the MapReduce model. This development was
known as Apache Hadoop YARN:\@ Yet Another Resource Negotiator, which can be thought of as an operating system sitting
atop of the available Hadoop resources~\cite{vavilapalli_apache_2013}. The abstraction YARN provides facilitated the
development of much more advanced, and non-MapReduce technologies which have since become widely used parts of the
Hadoop ecosystem~\cite{harrison_hadoops_2012}.

% subsection apache_hadoop (end)

\subsection{Realtime data processing} % (fold)
\label{sub:prop_realtime_data_processing}

One of the major limitations of Hadoop, and the MapReduce model in general, soon became obvious:\@ MapReduce was designed
with the goal of being able to process batches of data, hence, given Hadoop's dominance, batched data processing was the
focal point of the entire distributed data processing domain~\cite{kamburugamuve_survey_2014}. Essentially, batched data
processing is where data gets collected first into large enough batches before being processed all-at-once. The point of
processing in such a way is so there would be less overheads than attempting to process each individual datum as it
arrives. For a lot of use-cases this was, and still is, fine as there were no other drawbacks apart from a high level of
latency between the stages of when the data arrives and when it gets processed. However, for other applications, such as
stock trading, sensor monitoring, and web traffic processing, a more low-latency, realtime solution was
needed~\cite{kamburugamuve_survey_2014}.

Soon, many solutions, with different use-cases and design goals, were developed in the area of distributed stream
processing systems (DSPS). Given the Hadoop ecosystem that was already widely adopted, most of these DSPSs were built
upon the still new YARN layer, ensuring overall compatibility with the Hadoop ecosystem, and the underlying HDFS. Some
examples of such projects include the beforementioned Apache Storm, currently being used at Twitter,
Inc.~\cite{toshniwal_stormtwitter_2014}, among many other companies. Also up-and-coming projects, such as Apache Samza
which is a recently open-sourced project, currently being used in production at LinkedIn Corporation~\cite{web:Samza}.

% subsection realtime_data_processing (end)

\subsection{Future research} % (fold)
\label{sub:the_future}

While the overall area of big data processing has definitely been moving at a very fast pace in the last decade, the
area focused on realtime big data processing is still relatively young and shows much potential for further growth in
the way of research. As of writing, there are a considerable amount DSPS technologies available and in active
development, and are fast gaining adoption in industry.

While the various DSPS technologies available offer much needed realtime data stream processing functionality, it is
rather confusing for the end-user to differentiate between which of the technologies would be best given the users'
specific use-case and the class of data they are working with.

Currently, real time data stream processing is presented in most of the major DSPS technologies as a collection of
steps. For example, Apache Storm's processing topologies are made up of the ``bolt'' processing step abstraction along
with Apache Samza's processing model being made up of their ``task'' abstractions~\cite{kamburugamuve_survey_2014}.
Hence, with the existence of various DSPS technologies within the Hadoop ecosystem and elsewhere, and the idea of data
stream processing as a collection of processing steps, the DSPS components can be set up in a pipeline topology for
general data processing. The idea behind this pipeline being that each step along the way in the pipeline can be made up
of loosely related DSPS technologies, depending on the class of data needed to be processed. There is no fixed pipeline;
the general model should be DSPS-agnostic.

There has recently been an attempt at introducing a DSPS-agnostic architecture, known as the Lambda
architecture~\cite{marz2013principles}, that is currently gaining traction in the academic
community~\cite{islam_cloud_2014}~\cite{liu_survey_2014}.

We propose looking into the Lambda architecture, and similar attempts, as inspirations for our research project that
will  produce a set of processing recommendations for given data classes and, from those recommendations, the
construction of a heterogeneous data processing pipeline.

% subsection the_future (end)

% section research_context (end)


\newpage


\section{Objectives} % (fold)
\label{sec:objectives}

\subsection{Research questions} % (fold)
\label{sub:research_questions}

The following research questions will be the main focus of our project:

\begin{enumerate}
  \item\label{item:taxonomy} What characteristics of data systems can be identified to develop a data class taxonomy
  for real time big data processing?
  \item\label{item:recommendations} How can the taxonomy, stated in~\listref{item:taxonomy}, be utilised to provide a set
  of recommendations in designing a pipeline of data processing components to support a particular data system's
  processing requirements?
  \item\label{item:pipeline} How can the recommendations be used in practice to create an appropriate instance of a realtime
  data processing pipeline from existing DSPS technologies?
\end{enumerate}

Additionally, after answering each of these preliminary research questions, we will want to properly implement the
theoretical discoveries from each stage. We do this with the goal of achieving some deployable pipeline that can be then
be used in the testing and overall evaluation stages.

Note that the methodology behind how we are going to answer these questions is given in~\sectref{sec:methodology}.

% subsection research_questions (end)


\subsection{Research aims} % (fold)
\label{sub:research_aims}

The main aim or goal of this research project is to develop a set of recommendations that define exactly how certain
types, or classes, of data should be processed. These recommendations can then be used to specify particular DSPS technology
that can be used to make up a realtime data processing pipeline. The purpose of the pipeline being to take data from
arbitrary sources, process it in some specified way, then store the needed results on some storage medium, \eg HDFS.

Relating back to the first research question, to achieve the goal of developing a set of processing recommendations for
specific classes of data, we first aim to discover and implement a classification model for the purpose of
classifying different types of data. To implement the entire pipeline, this classification stage will need to happen early
on, hence will be one of our first aims we attempt to satisfy.

By the end of the project, we aim to have a proof-of-concept implementation of the pipeline working on the National
eResearch Collaboration Tools and Resources (NeCTAR) cloud~\cite{web:Nectar}. Further details regarding NeCTAR can be
found in~\sectref{sub:use_of_nectar_cloud_services} and~\sectref{sub:special_facilities_required}. Further details can be found on the
implementation of the pipeline in~\sectref{sec:expected_outcomes}.

We aim to be able to automate the formulation of some NeCTAR-compatible scripts, based on the data processing
recommendations. These scripts will be produced with the aim of enabling NeCTAR end-users to be able to deploy a
specific variation of the pipeline on their own NeCTAR instances. The scripts, and the pipelines they produce, will vary in
which DSPS technologies make up the pipeline for the given use-case. The use-case being for the specific class of data that
they are attempting to process.

Further detail on the project deliverables based upon these aims can be found in~\sectref{sec:expected_outcomes}.

% subsection research_aims (end)

% section objectives (end)


\newpage


\section{Methodology} % (fold)
\label{sec:methodology}

\subsection{Data classification method} % (fold)
\label{sub:data_classification_method}

For the research methodology surrounding the data classification method, we will employ a qualitative classification
method with the aim of producing a taxonomy of the different classes of data. This will allow us to clearly show the
requirements needed for processing each of the specific classes of data. Similarly, producing a taxonomy for a range of
different open-source DSPS technologies will allow us to show the data requirements for each specific DSPS. The purpose
of this taxonomy of DSPS technologies being so that we can directly form recommendations for the processing of specific
classes of data, relating such data classes with specific DSPS technologies that would be best suited for the given
task.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{img/taxonomy.png}
  \caption{Example data class and DSPS taxonomies, along with the mappings between them. Note that for simplification
  purposes, not all mappings are shown.}
\label{fig:taxonomy}
\end{figure}

As can be seen in~\figref{fig:taxonomy}, after we develop taxonomies for the classes of data and DSPS technologies, we
will attempt to map specific data classes to specific DSPS technologies. This mapping will form the basis of our set of
processing recommendations. Note that it is possible that different data classes may be mapped to the same DSPS technology.

From preliminary research for this project, we have discovered that there is a relatively small set of possible DSPS
technologies currently available to choose from. Hence, regardless of the number of different classes of data, multiple
different classes may have to be given the same DSPS recommendations, effectively limiting the number of data
classes. This makes the task of employing a data classification method much more simple in the context of this project.

% subsection data_classification_method (end)

\subsection{Data processing recommendations} % (fold)
\label{sub:data_processing_recommendations}

As stated in~\listref{item:recommendations}, in~\sectref{sub:research_questions}, we will formulate specific processing
recommendations for each given class of data. An example of these recommendations would be for data displaying
properties such as those of belonging to a graph data class. For this data class, we would recommend the usage of the
GraphX abstraction on top of the Apache Spark DSPS for processing, given GraphX's suitability for the processing of
graph data~\cite{DBLP:journals/corr/XinCDGFS14}.

% TODO: flow diagram of this example

These recommendations will be based directly off the data class and DSPS taxonomies that we will produce, as discussed
in~\sectref{sub:data_classification_method}.

% subsection data_processing_recommendations (end)

\subsection{Use of NeCTAR cloud services for evaluation} % (fold)
\label{sub:use_of_nectar_cloud_services}

One of the key parts of our research methodology will be the applied use of the National eResearch Collaboration Tools
and Resources cloud (NeCTAR)~\cite{web:Nectar}. Access to this cloud will facilitate the majority of applied work that
happens in this project, including the testing of existing big data stream processing technologies along with the
evaluation of our project's technical outcomes. It will also serve as the target platform for the implementation and
deployment of our pipeline.

To give a brief overview of NeCTAR, NeCTAR is a \$47 million (AUD) project funded by the Australian government to
facilitate Australian eResearch through providing shared Cloud infrastructures, among other
facilities~\cite{sinnott_towards_2011}.

As of writing, we have acquired two NeCTAR Cloud instances for this project's use. The instances having 16 shared
cores, 6400 hours of processing time, and one terabyte of shared volume storage. Going by initial estimates, these
requested resources should suffice for the scope of this research project. These resources are further touched on
in~\sectref{sub:special_facilities_required}.

Our NeCTAR instances will be used for a range of different tasks relating to testing and evaluation. Initially, we will
be installing different DSPS technologies on NeCTAR for the qualitative evaluation stage mentioned
in~\sectref{sub:data_classification_method}. This will be performed with the purpose of producing our taxonomy of DSPS
technologies. Secondly, we will use NeCTAR to construct instances of our data stream processing pipeline on, using the
available NeCTAR scripting environment. This will allow us to test the implemented pipeline and perform our final
evaluation of the resulting implementation.

From this testing and evaluation of our pipeline instances on NeCTAR, we will produce NeCTAR-compatible scripts for the
purpose of deploying the pipeline on NeCTAR cloud instances. This will allow any NeCTAR user to deploy instances of our
pipeline on their own account. These scripts are further touched on in~\sectref{sec:expected_outcomes}.

% subsection use_of_nectar_cloud_services (end)

% section methodology (end)


\newpage


\section{Research Design} % (fold)
\label{sec:research_design}

\subsection{Proposed thesis chapter headings} % (fold)
\label{sub:proposed_thesis_chapter_headings}

The proposed structure of the thesis is as follows:

\begin{enumerate}
  \item Introduction
  \begin{enumerate}[label*=\arabic*.]
    \item Overview
    \item Background
    \item Research problem
    \item Research questions
    \item Research scope
    \item Conclusion and thesis structure
  \end{enumerate}
  \item Literature Review
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Big data in industry and academia
    \item Batch data processing
    \item Overview of Hadoop ecosystem
    \item Realtime data processing
    \item Overview of realtime data processing technologies
    \item Disruptive research in big data
    \item Conclusion
  \end{enumerate}
  \item Streaming Data Processing Pipeline Model
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Taxonomy of streaming data systems
    \item Application of taxonomy to build set of recommendations
    \item Composing recommendations into pipeline
    \item Overview of pipeline
    \item Usage of pipeline
    \item Conclusion
  \end{enumerate}
  \item Implementation
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Implementation environment
    \item Use cases for implementation
    \item Data processing technologies for pipeline
    \item Implementation of pipeline in NeCTAR cloud
    \item Conclusion
  \end{enumerate}
  \item Discussion and Evaluation
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Performance evaluation
    \item Discussion
    \item Conclusion
  \end{enumerate}
  \item Conclusion
  \begin{enumerate}[label*=\arabic*.]
    \item Overview
    \item Research contributions
    \item Research limitations
    \item Future research
  \end{enumerate}
  \item Reference List
  \item Glossary
  \item Appendices
\end{enumerate}

% subsection proposed_thesis_chapter_headings (end)

\subsection{Timeline} % (fold)
\label{sub:timeline}

The following is a preliminary estimated timeline of the proposed research project:

\begin{center}
\begin{tabular}{ |l|l| }
  \hline
  \textbf{Task / Deliverable}           & \textbf{Deadline} \\ \hline
  First meeting with supervisors        & 2014-07-29        \\ \hline
  Scoping finalised                     & 2014-08-11        \\ \hline
  Research proposal draft submission    & 2014-09-01        \\ \hline
  Research proposal final submission    & 2014-09-05        \\ \hline
  Preliminary research complete         & 2014-10-16        \\ \hline
  Literature review draft submission    & 2014-10-31        \\ \hline
  Interim presentation                  & 2014-11-03        \\ \hline
  Literature review final submission    & 2014-11-07        \\ \hline
  Qualitative comparisons complete      & 2014-12-07        \\ \hline
  Data classification method complete   & 2015-01-01        \\ \hline
  Data processing recommendations due   & 2015-01-28        \\ \hline
  NeCTAR script implementation due      & 2015-02-28        \\ \hline
  Testing of pipeline on NeCTAR         & 2015-03-15        \\ \hline
  Evaluation of pipeline system         & 2015-04-01        \\ \hline
  Thesis draft submission               & 2015-05-29        \\ \hline
  Final presentation                    & 2015-06-08        \\ \hline
  Thesis final submission               & 2015-06-19        \\ \hline
\end{tabular}
\end{center}

Note that the above is simply a proposed timeline, and it is highly probable that this will be subject to change as the
project progresses.

% subsection timeline (end)

\subsection{Potential difficulties} % (fold)
\label{sub:potential_difficulties}

While we believe that most components of this project are very much feasible given the time and resources we have been
allocated so far, we have identified a small number of possible difficulties that may be encountered as the project
progresses. The most obvious difficulty so far that we have identified is the need to acquire a substantial amount of
data that we can use for both during the testing and the evaluation stages of the project. As this data will be used to
test our data classification methods and evaluate our pipeline deployed in the cloud, it will need to be diverse. By
diverse, what we mean is it must display heterogeneity in terms of its type and origin; data from many different sources
would be ideal.

Currently we have no concrete leads on the acquisition of this data, although we will look into collaboration with other
data-based research projects ongoing at Monash University. We also are yet to explore freely available data sets, such
as the Enron corpus email dataset~\cite{klimt2004introducing}, although these may definitely be taken into consideration
at a later stage in the project in the case that data acquisition from within Monash University proves infeasible.

% subsection potential_difficulties (end)

\subsection{Special facilities required} % (fold)
\label{sub:special_facilities_required}

As we are aiming to deploy a proof-of-concept of this pipeline, the main special facility needed access to is a cloud
solution that enables us to install and test our pipeline. For this, we have already been granted access for what we are
planning to do in this project on the National eResearch Collaboration Tools and Resources (NeCTAR)
cloud~\cite{web:Nectar}. This cloud is funded by the Australian Government and available to Australian researchers in
many different disciplines.

With access to this cloud for the duration of this project, we will be able to install and perform qualitative
comparisons between the numerous realtime data processing solutions available as of now. This will assist us in making
our recommendations for the pipeline based on the classification of particular set of data.

This access to cloud resources at NeCTAR will also facilitate our later testing and evaluation stages of the project,
where we will be hoping to test the pipeline with real heterogeneous data. This is all explained in greater detail
in~\sectref{sub:use_of_nectar_cloud_services}.

% subsection special_facilities_required (end)

% section research_design (end)


\newpage


\section{Expected Outcomes} % (fold)
\label{sec:expected_outcomes}

The expected outcomes of this project include both technical contributions and theoretical contributions; the technical
outcomes of the project essentially being implementations of the theoretical outcomes.

Our main theoretical contribution will be the realtime processing recommendations we produce for specific classes of
data. These recommendations will recommend specific realtime data processing technologies for use within the pipeline to
process the given data. These recommendations will be sourced from our initial studies into qualitative data classification
producing the taxonomies of both classes of data, and DSPS technologies, earlier mentioned in~\sectref{sub:data_classification_method}.

Looking at the project's outcomes in terms of technical contributions, they directly relate back to the theoretical
contributions. The main technical contribution will be NeCTAR template scripts which enable the deployment of the
pipeline on the NeCTAR cloud. These scripts will be constructed based upon the recommendations produced for specific
dataset classes.

To summarise, the expected outcomes of this project include the following contributions:

\begin{itemize}
  \item A taxonomy of different classes of data.
  \item A taxonomy of different DSPS technologies.
  \item A set of recommendations for specific classes of data, recommending how each class should be processed in realtime.
  \item NeCTAR-compatible scripts allowing the deployment of the recommended pipeline instances on the NeCTAR cloud.
\end{itemize}

All of these contributions will be assembled together to make complete instances of a realtime heterogeneous data
stream processing pipeline system for many different types of data.

% section expected_outcomes (end)



